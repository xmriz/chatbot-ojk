{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **OJKGPT**\n",
    "\n",
    "This is the Jupyter Notebook for the development of the 1st version of OJKGPT for the showcase demo capabilites to wealth team program. <br>\n",
    "In this development, we use several data sources for enriching the RAG system of the chatbot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.models_definer import ModelName\n",
    "\n",
    "# storing or not\n",
    "OCR_TRESHOLD = 0.98\n",
    "TOP_K = 3\n",
    "NUM_BATCH_EVAL = 10\n",
    "STORE = False\n",
    "DELETE = False\n",
    "EVAL = False\n",
    "model_name = ModelName.AZURE_OPENAI\n",
    "model_name_eval = ModelName.OPENAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LLM Models Define**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from utils.models_definer import get_llm_and_embedding\n",
    "\n",
    "# ollama/openai/azure_openai\n",
    "llm,embedding_llm = get_llm_and_embedding(model_name=model_name)\n",
    "\n",
    "llm_eval = get_llm_and_embedding(model_name=model_name_eval)[0]\n",
    "\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embedding_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loading Documents**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Document Reader and Node Parser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.documents_reader import read_documents\n",
    "from utils.node_parser import parse_nodes\n",
    "\n",
    "path = './data'\n",
    "\n",
    "if STORE:\n",
    "    docs = read_documents(path=path, ocr_treshold=OCR_TRESHOLD)\n",
    "    nodes = parse_nodes(documents=docs, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Indexing & Storing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the vector index completed.\n"
     ]
    }
   ],
   "source": [
    "from utils.index_store import (store_vector_index, load_vector_index)\n",
    "\n",
    "# store\n",
    "if STORE:\n",
    "    vector_index = store_vector_index(nodes=nodes,embed_model=embedding_llm, delete=DELETE)\n",
    "# load\n",
    "else:\n",
    "    vector_index = load_vector_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Querying**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Retriever**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever = vector_index.as_retriever(similarity_top_k=TOP_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "qa_prompt = \"\"\"\\\n",
    "Context information is below.\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "Given the context information and not prior knowledge, \\\n",
    "answer the query asking about banking compliance in Indonesia. \n",
    "Answer the question based on the context information.\n",
    "ALWAYS ANSWER WITH USER'S LANGUAGE.\n",
    "Please provide your answer with [regulation_number](file_url) in metadata \n",
    "(if possible) in the following format:\n",
    "\n",
    "---------------------\n",
    "Answer... \\n\\n\n",
    "Source: [regulation_number](file_url) \\n\n",
    "---------------------\n",
    "\n",
    "Query: {query_str}\n",
    "Answer: \\\n",
    "\"\"\"\n",
    "\n",
    "qa_prompt_tmpl = PromptTemplate(qa_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Query Engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "vector_query_engine = RetrieverQueryEngine.from_args(retriever=vector_retriever,llm=llm,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_prompt_tmpl}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:text_qa_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context information is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query asking about banking compliance in Indonesia. \n",
      "Answer the question based on the context information.\n",
      "ALWAYS ANSWER WITH USER'S LANGUAGE.\n",
      "Please provide your answer with [regulation_number](file_url) in metadata \n",
      "(if possible) in the following format:\n",
      "\n",
      "---------------------\n",
      "Answer... \n",
      "\n",
      "\n",
      "Source: [regulation_number](file_url) \n",
      "\n",
      "---------------------\n",
      "\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:refine_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original query is as follows: {query_str}\n",
      "We have provided an existing answer: {existing_answer}\n",
      "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "------------\n",
      "{context_msg}\n",
      "------------\n",
      "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
      "Refined Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.prompt_display import display_prompt_dict\n",
    "\n",
    "prompts_dict = vector_query_engine.get_prompts()\n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"Apa judul peraturan 7/33/PBI/2005?\" # Pencabutan atas Peraturan Bank Indonesia Nomor 5/17/PBI/2003 tentang Persyaratan dan Tata Cara Pelaksanaan Jaminan Pemerintah terhadap Kewajiban Pembayaran Bank Perkreditan Rakyat\n",
    "b = \"Kapan surat edaran No. 15/26/DPbS mulai berlaku?\" # 1 Agustus 2013.\n",
    "c = \"Siapa nama dan jabatannya yang menandatangani surat dengan nomor 1/SEOJK.04/2013?\" # NURHAIDA, kepala eksekutif pengawas pasar modal\n",
    "d = \"Saya ingin menyelenggarakan kegiatan pasar modal berikan saya nomor surat yang membahas mengenai hal ini!\" # Peraturan Pemerintah Nomor 12 Tahun 2004\n",
    "e = \"Berapa persen jaminan moneter pada tanggal 20 Agustus 1958?\" # 7,3%\n",
    "f = \"Surat edaran nomor berapa yang mengatur bank umum syariah dan unit usaha syariah?\" # 15/26/DPbS\n",
    "g = \"Apa kepanjangan dari PAPSI?\" # Pedoman Akuntansi Perbankan Syariah Indonesia\n",
    "h = \"apa judul peraturan nomor 112/KMK.03/2001?\" # Keputusan Menteri Keuangan tentang Pemotongan Pajak Penghasil Pasal 21 atas Penghasilan berupa Uang Pesangon, Uang Tebusan Pensiun, dan Tunjangan Hari Tua atau Jaminan Hari Tua\n",
    "i = \"Saya ingin membuat sistem informasi lembaga jasa keuangan, berikan nomor regulasi dari peraturan yang membahas tentang manejemen risiko nya!\" # 4/POJK.05/2021\n",
    "j = \"Apa kepanjangan dari SWDKLLJ?\" # Sumbangan Wajib Dana Kecelakaan Lalu Lintas Jalan\n",
    "k = \"Berapa nilai SWDKLLJ dari sedan?\" # Rp. 140.000\n",
    "l = \"Apa latar belakang dari peraturan NOMOR 4/POJK.05/2021?\" # dalam bentuk list\n",
    "m = \"Apa itu LJKNB?\" # Lembaga Jasa Keuangan Non Bank\n",
    "n = \"Apakah KMK Nomor 462/KMK.04/1998 masih berlaku\" # tidak\n",
    "o = \"Apa itu Uang Pesangon?\" # penghasilan yang dibayarkan oleh pemberi kerja kepada karyawan dengan nama dan dalam bentuk apapun sehubungan dengan berakhirnya masa kerja atau terjadi pemutusan  hubungan kerja, termasuk uang penghargaan masa kerja dan uang  ganti kerugian\n",
    "p = \"Apa itu CKPN?\" # Cadangan Kerugian Penurunan Nilai.\n",
    "q = \"Kapan, dimana, dan oleh siapa surat nomor PER- 06/BL/2012 ditetapkan?\" # Surat nomor PER-06/BL/2012 ditetapkan pada tanggal 22 November 2012 di Jakarta oleh Ketua Badan Pengawas Pasar Modal dan Lembaga Keuangan.\n",
    "r = \"Apa kepanjangan PSAK?\" # Pernyataan Standar Akuntansi Keuangan\n",
    "s = \"Apa itu 'shahibul maal'?\" # Pemilik dana pihak ketiga\n",
    "\n",
    "query_str = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Nilai SWDKLLJ untuk sedan adalah Rp140.000,00 (seratus empat puluh ribu rupiah).\n",
       "\n",
       "Source: [36/PMK.010/2008](https://www.ojk.go.id/id/regulasi/Documents/Pages/PMK-Nomor-36PMK.010-Tahun-2008-tentang-Besar-Santunan-dan-Sumbangan-Wajib-Dana-Kecelakaan-Lalu-Lintas-Jalan/menas13_1389258036.pdf)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_response\n",
    "\n",
    "response_vector = vector_query_engine.query(query_str)\n",
    "display_response(response_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Chat Engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.storage.chat_store import SimpleChatStore\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "\n",
    "chat_store = SimpleChatStore()\n",
    "memory = ChatMemoryBuffer.from_defaults(\n",
    "    token_limit=10000,\n",
    "    chat_store=chat_store,\n",
    "    chat_store_key=\"user1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.agent.openai import OpenAIAgent\n",
    "# from llama_index.core.agent.legacy.react.base import ReActAgent\n",
    "from llama_index.core.chat_engine import CondenseQuestionChatEngine\n",
    "\n",
    "chat_engine = CondenseQuestionChatEngine.from_defaults(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    query_engine=vector_query_engine,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying with: Apa itu LJKNB?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** LJKNB stands for Lembaga Jasa Keuangan Nonbank, which refers to nonbank financial institutions in Indonesia. These institutions are required to implement risk management in the use of information technology, and they must establish an Information Technology Steering Committee if their total assets exceed Rp1,000,000,000,000,00 (one trillion rupiah). The committee should consist of directors responsible for IT units, directors or officials in charge of risk management, the highest-ranking officials in charge of IT units, and the highest-ranking officials in charge of IT user units."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_response\n",
    "\n",
    "response = chat_engine.chat(message=query_str)\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** e840f3a2-cc99-4719-b933-b0b79b5ec7ad<br>**Similarity:** 0.8018614649772644<br>**Text:** MENTERI KEUANGAN\n",
       "REPUBLIK INDONESIA\n",
       "-4-\n",
       " Mobil penumpang angkutan umum sampai dengan 1600 cc\n",
       "g. B...<br>**Metadata:** {'file_name': 'ojk-klasifikasi_bapepam-36_pmk_010_2008-26022008-pmk_nomor_36pmk_010_tahun_2008_tentang_besar_santunan_dan_sumbangan_wajib_dana_kecelakaan_lalu_lintas_jalan_menas13_1389258036_pdf.pdf', 'title': 'Peraturan Menteri Keuangan Nomor 36/PMK.010/2008 tentang Besar Santunan dan Sumbangan Wajib Dana Kecelakaan Lalu Lintas Jalan', 'sector': 'IKNB', 'subsector': 'Asuransi', 'regulation_type': 'Klasifikasi Bapepam', 'regulation_number': '36/PMK.010/2008', 'effective_date': '26 Februari 2008', 'retrieval_score': 0.9084663987159729}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 10989a33-e3d7-4d3d-8f5c-88ad29732ba8<br>**Similarity:** 0.707891047000885<br>**Text:** MENTERI KEUANGAN\n",
       "REPUBLIK INDONESIA\n",
       "memperoleh santunan sebesar Rp 25.000.000,00 (dua puluh lima\n",
       "...<br>**Metadata:** {'file_name': 'ojk-klasifikasi_bapepam-36_pmk_010_2008-26022008-pmk_nomor_36pmk_010_tahun_2008_tentang_besar_santunan_dan_sumbangan_wajib_dana_kecelakaan_lalu_lintas_jalan_menas13_1389258036_pdf.pdf', 'title': 'Peraturan Menteri Keuangan Nomor 36/PMK.010/2008 tentang Besar Santunan dan Sumbangan Wajib Dana Kecelakaan Lalu Lintas Jalan', 'sector': 'IKNB', 'subsector': 'Asuransi', 'regulation_type': 'Klasifikasi Bapepam', 'regulation_number': '36/PMK.010/2008', 'effective_date': '26 Februari 2008', 'retrieval_score': 0.9090815782546997}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 67d00445-e031-4d07-a3ed-a224c28a62a3<br>**Similarity:** 0.6666857600212097<br>**Text:** REPUBLIK INDONESIA\n",
       " Penyelenggaraan Usaha Perasuransian (Lembaran Negara Republik\n",
       "Indonesia Tahun...<br>**Metadata:** {'file_name': 'ojk-klasifikasi_bapepam-36_pmk_010_2008-26022008-pmk_nomor_36pmk_010_tahun_2008_tentang_besar_santunan_dan_sumbangan_wajib_dana_kecelakaan_lalu_lintas_jalan_menas13_1389258036_pdf.pdf', 'title': 'Peraturan Menteri Keuangan Nomor 36/PMK.010/2008 tentang Besar Santunan dan Sumbangan Wajib Dana Kecelakaan Lalu Lintas Jalan', 'sector': 'IKNB', 'subsector': 'Asuransi', 'regulation_type': 'Klasifikasi Bapepam', 'regulation_number': '36/PMK.010/2008', 'effective_date': '26 Februari 2008', 'retrieval_score': 0.8981241583824158}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "for node in response.source_nodes:\n",
    "    display_source_node(node, show_source_metadata=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_store_string = chat_store.json()\n",
    "loaded_chat_store = SimpleChatStore.parse_raw(chat_store_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# check directory exist\n",
    "if not os.path.exists(\"./json_data\"):\n",
    "    os.makedirs(\"./json_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import (\n",
    "    generate_question_context_pairs,\n",
    "    EmbeddingQAFinetuneDataset,\n",
    ")\n",
    "if EVAL:\n",
    "    if STORE:\n",
    "        qa_dataset = generate_question_context_pairs(\n",
    "            nodes=nodes,\n",
    "            llm=llm_eval,\n",
    "            num_questions_per_chunk=2,\n",
    "        )\n",
    "        qa_dataset.save_json(\"./json_data/pg_eval_dataset.json\")\n",
    "    else:\n",
    "        qa_dataset = EmbeddingQAFinetuneDataset.from_json(\"./json_data/pg_eval_dataset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Retrieval Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"hit_rate\", \"mrr\", \"precision\", \"recall\", \"ap\", \"ndcg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluator import get_retrieval_eval_df\n",
    "\n",
    "if EVAL:\n",
    "    vector_retrieval_eval_results = await get_retrieval_eval_df(name=f\"Top-{TOP_K} Eval\", metrics=metrics, retriever=vector_retriever, qa_dataset=qa_dataset)\n",
    "    display(vector_retrieval_eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Response Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import (\n",
    "    FaithfulnessEvaluator,\n",
    "    RelevancyEvaluator,\n",
    ")\n",
    "\n",
    "if EVAL:\n",
    "    # model for evaluation\n",
    "    relevancy_evaluator = RelevancyEvaluator(llm=llm_eval)\n",
    "    faithfullness_evaluator = FaithfulnessEvaluator(llm=llm_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Faithfulness Evaluator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluator import get_response_eval_df\n",
    "\n",
    "if EVAL:\n",
    "    vector_faithfullness_eval_result = faithfullness_evaluator.evaluate_response(response=response_vector, query=query_str)\n",
    "    display(get_response_eval_df(query=query_str, response=response_vector, eval_result=vector_faithfullness_eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Source Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluator import get_response_eval_sources_df\n",
    "\n",
    "if EVAL:\n",
    "    relevancy_eval_sources = get_response_eval_sources_df(query=query_str, response=response_vector, evaluator=faithfullness_evaluator)\n",
    "    display(relevancy_eval_sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Relevancy Evaluator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVAL:\n",
    "    relevancy_eval_result = relevancy_evaluator.evaluate_response(\n",
    "        query=query_str, response=response_vector\n",
    "    )\n",
    "\n",
    "    display(get_response_eval_df(query=query_str, response=response_vector, eval_result=relevancy_eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Source Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluator import get_response_eval_sources_df\n",
    "\n",
    "if EVAL:\n",
    "    relevancy_eval_sources = get_response_eval_sources_df(query=query_str, response=response_vector, evaluator=relevancy_evaluator)\n",
    "    display(relevancy_eval_sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Batch Evaluator (Faithfulness, Relevancy, Correctness)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import BatchEvalRunner\n",
    "from utils.evaluator import get_batch_eval_results\n",
    "from utils.evaluator import get_batch_eval_df\n",
    "\n",
    "if EVAL:\n",
    "    runner = BatchEvalRunner(\n",
    "        {\n",
    "            \"faithfulness\": faithfullness_evaluator, \n",
    "            \"relevancy\": relevancy_evaluator,\n",
    "        },\n",
    "        workers=8,\n",
    "    )\n",
    "\n",
    "    vector_eval_results = await get_batch_eval_results(runner=runner, qa_dataset=qa_dataset, query_engine=vector_query_engine, num_queries=NUM_BATCH_EVAL)\n",
    "    display(get_batch_eval_df(vector_eval_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
