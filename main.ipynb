{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **OJKGPT**\n",
    "\n",
    "This is the Jupyter Notebook for the development of the 1st version of OJKGPT for the showcase demo capabilites to wealth team program. <br>\n",
    "In this development, we use several data sources for enriching the RAG system of the chatbot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.models_definer import ModelName\n",
    "\n",
    "# storing or not\n",
    "OCR_TRESHOLD = 0.98\n",
    "TOP_K = 3\n",
    "NUM_BATCH_EVAL = 20\n",
    "STORE = False\n",
    "DELETE = True\n",
    "EVAL = False\n",
    "model_name = ModelName.AZURE_OPENAI\n",
    "model_name_eval = ModelName.OPENAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LLM Models Define**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from utils.models_definer import get_llm_and_embedding\n",
    "\n",
    "# ollama/openai/azure_openai\n",
    "llm, embedding_llm = get_llm_and_embedding(model_name=model_name)\n",
    "\n",
    "llm_eval = get_llm_and_embedding(model_name=model_name_eval)[0]\n",
    "\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embedding_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loading Documents**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Document Reader and Node Parser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.documents_reader import read_documents\n",
    "from utils.node_parser import parse_nodes\n",
    "\n",
    "path = './data'\n",
    "\n",
    "if STORE:\n",
    "    docs = read_documents(path=path, ocr_treshold=OCR_TRESHOLD)\n",
    "    nodes = parse_nodes(documents=docs, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Indexing & Storing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the vector index completed.\n",
      "Loading the summary index completed.\n"
     ]
    }
   ],
   "source": [
    "from utils.index_store import (store_vector_index, load_vector_index, store_summary_index, load_summary_index)\n",
    "\n",
    "# store\n",
    "if STORE:\n",
    "    vector_index = store_vector_index(nodes=nodes,embed_model=embedding_llm, delete=DELETE)\n",
    "    summary_index = store_summary_index(nodes=nodes,llm=llm, delete=DELETE,embed_model=embedding_llm)\n",
    "# load\n",
    "else:\n",
    "    vector_index = load_vector_index()\n",
    "    summary_index = load_summary_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.document_summary.base.DocumentSummaryIndex at 0x299e89c1c30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary_index.get_document_summary(doc_id='c6538032-b87d-42c5-91c2-83c8e62ed305')\n",
    "summary_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Querying**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Retriever**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.document_summary import (\n",
    "    DocumentSummaryIndexLLMRetriever\n",
    ")\n",
    "from llama_index.core.retrievers import RecursiveRetriever\n",
    "\n",
    "vector_retriever = vector_index.as_retriever(similarity_top_k=TOP_K)\n",
    "\n",
    "recursive_retriever = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever}\n",
    ")\n",
    "\n",
    "summary_retriever = DocumentSummaryIndexLLMRetriever(\n",
    "    index=summary_index,\n",
    "    choice_top_k=TOP_K,\n",
    "    # embed_model=embedding_llm,\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Query Engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.postprocessor.colbert_rerank import ColbertRerank\n",
    "\n",
    "colbert_reranker = ColbertRerank(\n",
    "    top_n=5,\n",
    "    model=\"colbert-ir/colbertv2.0\",\n",
    "    tokenizer=\"colbert-ir/colbertv2.0\",\n",
    "    keep_retrieval_score=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core import get_response_synthesizer\n",
    "import time\n",
    "\n",
    "vector_query_engine = RetrieverQueryEngine.from_args(retriever=recursive_retriever,llm=llm, node_postprocessors=[colbert_reranker])\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(response_mode=\"tree_summarize\")\n",
    "list_query_engine = RetrieverQueryEngine.from_args(retriever=summary_retriever,llm=llm_eval, node_postprocessors=[colbert_reranker], )\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"Apa judul peraturan 7/33/PBI/2005?\" # Pencabutan atas Peraturan Bank Indonesia Nomor 5/17/PBI/2003 tentang Persyaratan dan Tata Cara Pelaksanaan Jaminan Pemerintah terhadap Kewajiban Pembayaran Bank Perkreditan Rakyat\n",
    "b = \"Kapan surat edaran No. 15/26/DPbS mulai berlaku?\" # 1 Agustus 2013.\n",
    "c = \"Siapa nama dan jabatannya yang menandatangani surat dengan nomor 1/SEOJK.04/2013?\" # NURHAIDA, kepala eksekutif pengawas pasar modal\n",
    "d = \"Saya ingin menyelenggarakan kegiatan pasar modal berikan saya nomor surat yang membahas mengenai hal ini!\" # Peraturan Pemerintah Nomor 12 Tahun 2004\n",
    "e = \"Berapa persen jaminan moneter pada tanggal 20 Agustus 1958?\" # 7,3%\n",
    "f = \"Surat edaran nomor berapa yang mengatur bank umum syariah dan unit usaha syariah?\" # 15/26/DPbS\n",
    "g = \"Apa kepanjangan dari PAPSI?\" # Pedoman Akuntansi Perbankan Syariah Indonesia\n",
    "h = \"apa judul peraturan nomor 112/KMK.03/2001?\" # Keputusan Menteri Keuangan tentang Pemotongan Pajak Penghasil Pasal 21 atas Penghasilan berupa Uang Pesangon, Uang Tebusan Pensiun, dan Tunjangan Hari Tua atau Jaminan Hari Tua\n",
    "i = \"Saya ingin membuat sistem informasi lembaga jasa keuangan, berikan nomor regulasi dari peraturan yang membahas tentang manejemen risiko nya!\" # 4/POJK.05/2021\n",
    "j = \"Apa kepanjangan dari SWDKLLJ?\" # Sumbangan Wajib Dana Kecelakaan Lalu Lintas Jalan\n",
    "k = \"Berapa nilai SWDKLLJ mobil sedan?\" # Rp. 140.000\n",
    "l = \"Apa latar belakang dari peraturan NOMOR 4/POJK.05/2021?\" # dalam bentuk list\n",
    "m = \"Apa itu LJKNB?\" # Lembaga Jasa Keuangan Non Bank\n",
    "n = \"Apakah KMK Nomor 462/KMK.04/1998 masih berlaku\" # tidak\n",
    "o = \"Apa itu Uang Pesangon?\" # penghasilan yang dibayarkan oleh pemberi kerja kepada karyawan dengan nama dan dalam bentuk apapun sehubungan dengan berakhirnya masa kerja atau terjadi pemutusan  hubungan kerja, termasuk uang penghargaan masa kerja dan uang  ganti kerugian\n",
    "p = \"Apa itu CKPN?\" # Cadangan Kerugian Penurunan Nilai.\n",
    "q = \"Kapan, dimana, dan oleh siapa surat nomor PER- 06/BL/2012 ditetapkan?\" # Surat nomor PER-06/BL/2012 ditetapkan pada tanggal 22 November 2012 di Jakarta oleh Ketua Badan Pengawas Pasar Modal dan Lembaga Keuangan.\n",
    "r = \"Apa kepanjangan PSAK?\" # Pernyataan Standar Akuntansi Keuangan\n",
    "s = \"Apa itu 'shahibul maal'?\" # Pemilik dana pihak ketiga\n",
    "\n",
    "query_str = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Empty Response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_response\n",
    "\n",
    "response_vector = vector_query_engine.query(query_str)\n",
    "display_response(response_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "doc_id 3054841f-f2f1-4aef-bb62-5dfb9f42b841 not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response_summary \u001b[38;5;241m=\u001b[39m \u001b[43mlist_query_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m display_response(response_summary)\n",
      "File \u001b[1;32me:\\ITB\\Kerja Praktek\\project\\chatbot-ojk\\rag\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[0;32m    228\u001b[0m )\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32me:\\ITB\\Kerja Praktek\\project\\chatbot-ojk\\rag\\lib\\site-packages\\llama_index\\core\\base\\base_query_engine.py:52\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[1;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     51\u001b[0m         str_or_query_bundle \u001b[38;5;241m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[1;32m---> 52\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m     54\u001b[0m     QueryEndEvent(query\u001b[38;5;241m=\u001b[39mstr_or_query_bundle, response\u001b[38;5;241m=\u001b[39mquery_result)\n\u001b[0;32m     55\u001b[0m )\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "File \u001b[1;32me:\\ITB\\Kerja Praktek\\project\\chatbot-ojk\\rag\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[0;32m    228\u001b[0m )\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32me:\\ITB\\Kerja Praktek\\project\\chatbot-ojk\\rag\\lib\\site-packages\\llama_index\\core\\query_engine\\retriever_query_engine.py:189\u001b[0m, in \u001b[0;36mRetrieverQueryEngine._query\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Answer a query.\"\"\"\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    187\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mQUERY, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str}\n\u001b[0;32m    188\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m query_event:\n\u001b[1;32m--> 189\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_synthesizer\u001b[38;5;241m.\u001b[39msynthesize(\n\u001b[0;32m    191\u001b[0m         query\u001b[38;5;241m=\u001b[39mquery_bundle,\n\u001b[0;32m    192\u001b[0m         nodes\u001b[38;5;241m=\u001b[39mnodes,\n\u001b[0;32m    193\u001b[0m     )\n\u001b[0;32m    194\u001b[0m     query_event\u001b[38;5;241m.\u001b[39mon_end(payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mRESPONSE: response})\n",
      "File \u001b[1;32me:\\ITB\\Kerja Praktek\\project\\chatbot-ojk\\rag\\lib\\site-packages\\llama_index\\core\\query_engine\\retriever_query_engine.py:144\u001b[0m, in \u001b[0;36mRetrieverQueryEngine.retrieve\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretrieve\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_bundle: QueryBundle) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[NodeWithScore]:\n\u001b[1;32m--> 144\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_node_postprocessors(nodes, query_bundle\u001b[38;5;241m=\u001b[39mquery_bundle)\n",
      "File \u001b[1;32me:\\ITB\\Kerja Praktek\\project\\chatbot-ojk\\rag\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[0;32m    228\u001b[0m )\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32me:\\ITB\\Kerja Praktek\\project\\chatbot-ojk\\rag\\lib\\site-packages\\llama_index\\core\\base\\base_retriever.py:243\u001b[0m, in \u001b[0;36mBaseRetriever.retrieve\u001b[1;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mas_trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    240\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mRETRIEVE,\n\u001b[0;32m    241\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str},\n\u001b[0;32m    242\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m retrieve_event:\n\u001b[1;32m--> 243\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_recursive_retrieval(query_bundle, nodes)\n\u001b[0;32m    245\u001b[0m         retrieve_event\u001b[38;5;241m.\u001b[39mon_end(\n\u001b[0;32m    246\u001b[0m             payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mNODES: nodes},\n\u001b[0;32m    247\u001b[0m         )\n",
      "File \u001b[1;32me:\\ITB\\Kerja Praktek\\project\\chatbot-ojk\\rag\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[0;32m    228\u001b[0m )\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32me:\\ITB\\Kerja Praktek\\project\\chatbot-ojk\\rag\\lib\\site-packages\\llama_index\\core\\indices\\document_summary\\retrievers.py:89\u001b[0m, in \u001b[0;36mDocumentSummaryIndexLLMRetriever._retrieve\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(summary_ids), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_choice_batch_size):\n\u001b[0;32m     88\u001b[0m     summary_ids_batch \u001b[38;5;241m=\u001b[39m summary_ids[idx : idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_choice_batch_size]\n\u001b[1;32m---> 89\u001b[0m     summary_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_ids_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m     query_str \u001b[38;5;241m=\u001b[39m query_bundle\u001b[38;5;241m.\u001b[39mquery_str\n\u001b[0;32m     91\u001b[0m     fmt_batch_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_node_batch_fn(summary_nodes)\n",
      "File \u001b[1;32me:\\ITB\\Kerja Praktek\\project\\chatbot-ojk\\rag\\lib\\site-packages\\llama_index\\core\\storage\\docstore\\types.py:156\u001b[0m, in \u001b[0;36mBaseDocumentStore.get_nodes\u001b[1;34m(self, node_ids, raise_error)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_nodes\u001b[39m(\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m, node_ids: List[\u001b[38;5;28mstr\u001b[39m], raise_error: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    148\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BaseNode]:\n\u001b[0;32m    149\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get nodes from docstore.\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m \n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_node(node_id, raise_error\u001b[38;5;241m=\u001b[39mraise_error) \u001b[38;5;28;01mfor\u001b[39;00m node_id \u001b[38;5;129;01min\u001b[39;00m node_ids]\n",
      "File \u001b[1;32me:\\ITB\\Kerja Praktek\\project\\chatbot-ojk\\rag\\lib\\site-packages\\llama_index\\core\\storage\\docstore\\types.py:156\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_nodes\u001b[39m(\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m, node_ids: List[\u001b[38;5;28mstr\u001b[39m], raise_error: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    148\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BaseNode]:\n\u001b[0;32m    149\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get nodes from docstore.\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m \n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_error\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m node_id \u001b[38;5;129;01min\u001b[39;00m node_ids]\n",
      "File \u001b[1;32me:\\ITB\\Kerja Praktek\\project\\chatbot-ojk\\rag\\lib\\site-packages\\llama_index\\core\\storage\\docstore\\types.py:181\u001b[0m, in \u001b[0;36mBaseDocumentStore.get_node\u001b[1;34m(self, node_id, raise_error)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_node\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_id: \u001b[38;5;28mstr\u001b[39m, raise_error: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseNode:\n\u001b[0;32m    174\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get node from docstore.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m \n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc, BaseNode):\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a Node.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\ITB\\Kerja Praktek\\project\\chatbot-ojk\\rag\\lib\\site-packages\\llama_index\\core\\storage\\docstore\\keyval_docstore.py:360\u001b[0m, in \u001b[0;36mKVDocumentStore.get_document\u001b[1;34m(self, doc_id, raise_error)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m json \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[1;32m--> 360\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc_id \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: doc_id 3054841f-f2f1-4aef-bb62-5dfb9f42b841 not found."
     ]
    }
   ],
   "source": [
    "# response_summary = list_query_engine.query(query_str)\n",
    "# display_response(response_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# check directory exist\n",
    "if not os.path.exists(\"./json_data\"):\n",
    "    os.makedirs(\"./json_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import (\n",
    "    generate_question_context_pairs,\n",
    "    EmbeddingQAFinetuneDataset,\n",
    ")\n",
    "if EVAL:\n",
    "    if STORE:\n",
    "        qa_dataset = generate_question_context_pairs(\n",
    "            nodes=nodes,\n",
    "            llm=llm_eval,\n",
    "            num_questions_per_chunk=2,\n",
    "        )\n",
    "        qa_dataset.save_json(\"./json_data/pg_eval_dataset.json\")\n",
    "    else:\n",
    "        qa_dataset = EmbeddingQAFinetuneDataset.from_json(\"./json_data/pg_eval_dataset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Retrieval Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"hit_rate\", \"mrr\", \"precision\", \"recall\", \"ap\", \"ndcg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluator import get_retrieval_eval_df\n",
    "\n",
    "if EVAL:\n",
    "    vector_retrieval_eval_results = await get_retrieval_eval_df(name=f\"Top-{TOP_K} Eval\", metrics=metrics, retriever=vector_retriever, qa_dataset=qa_dataset)\n",
    "    display(vector_retrieval_eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Response Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import (\n",
    "    FaithfulnessEvaluator,\n",
    "    RelevancyEvaluator,\n",
    ")\n",
    "\n",
    "if EVAL:\n",
    "    # model for evaluation\n",
    "    relevancy_evaluator = RelevancyEvaluator(llm=llm_eval)\n",
    "    faithfullness_evaluator = FaithfulnessEvaluator(llm=llm_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Faithfulness Evaluator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluator import get_response_eval_df\n",
    "\n",
    "if EVAL:\n",
    "    vector_faithfullness_eval_result = faithfullness_evaluator.evaluate_response(response=response_vector, query=query_str)\n",
    "    summary_faithfullness_eval_result = faithfullness_evaluator.evaluate_response(response=response_summary, query=query_str)\n",
    "    display(get_response_eval_df(query=query_str, response=response_vector, eval_result=vector_faithfullness_eval_result))\n",
    "    display(get_response_eval_df(query=query_str, response=response_summary, eval_result=summary_faithfullness_eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Source Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluator import get_response_eval_sources_df\n",
    "\n",
    "if EVAL:\n",
    "    relevancy_eval_sources = get_response_eval_sources_df(query=query_str, response=response_vector, evaluator=faithfullness_evaluator)\n",
    "    display(relevancy_eval_sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Relevancy Evaluator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVAL:\n",
    "    relevancy_eval_result = relevancy_evaluator.evaluate_response(\n",
    "        query=query_str, response=response_vector\n",
    "    )\n",
    "\n",
    "    display(get_response_eval_df(query=query_str, response=response_vector, eval_result=relevancy_eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Source Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluator import get_response_eval_sources_df\n",
    "\n",
    "if EVAL:\n",
    "    relevancy_eval_sources = get_response_eval_sources_df(query=query_str, response=response_vector, evaluator=relevancy_evaluator)\n",
    "    display(relevancy_eval_sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Batch Evaluator (Faithfulness, Relevancy, Correctness)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import BatchEvalRunner\n",
    "from utils.evaluator import get_batch_eval_results\n",
    "from utils.evaluator import get_batch_eval_df\n",
    "\n",
    "if EVAL:\n",
    "    runner = BatchEvalRunner(\n",
    "        {\n",
    "            \"faithfulness\": faithfullness_evaluator, \n",
    "            \"relevancy\": relevancy_evaluator,\n",
    "        },\n",
    "        workers=8,\n",
    "    )\n",
    "\n",
    "    vector_eval_results = await get_batch_eval_results(runner=runner, qa_dataset=qa_dataset, query_engine=vector_query_engine, num_queries=NUM_BATCH_EVAL)\n",
    "    summary_eval_results = await get_batch_eval_results(runner=runner, qa_dataset=qa_dataset, query_engine=list_query_engine, num_queries=NUM_BATCH_EVAL)\n",
    "    display(get_batch_eval_df(vector_eval_results))\n",
    "    display(get_batch_eval_df(summary_eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Build Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=vector_query_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"vector_tool\",\n",
    "            description=(\n",
    "                f\"Useful for retrieving specific context from the documents.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    QueryEngineTool(\n",
    "        query_engine=list_query_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"summary_tool\",\n",
    "            description=(\n",
    "                \"Useful for summarization questions related to the documents.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Anda adalah chatbot yang dapat membantu menjawab pertanyaan tentang berbagai jenis regulasi di Indonesia.\n",
    "\n",
    "Anda HARUS selalu menjawab dengan BAHASA QUERY.\n",
    "Anda TIDAK DIBENARKAN berimajinasi.\n",
    "Anda HANYA DIBENARKAN menjawab pertanyaan berdasarkan dokumen yang telah Anda pelajari.\n",
    "JANGAN MENGGUNAKAN informasi dari luar dokumen yang telah Anda pelajari.\n",
    "Anda memiliki akses ke query tools untuk membantu Anda menemukan informasi yang relevan di basis data regulasi.\n",
    "Berdasarkan informasi konteks dan bukan pengetahuan sebelumnya, jawablah pertanyaan HARUS menggunakan query tools yang tersedia.\n",
    "Gunakan riwayat percakapan sebelumnya atau konteks di atas untuk berinteraksi dan membantu pengguna.\n",
    "\n",
    "Anda memiliki akses ke query tools berikut: \n",
    "- **vector_tool**: Untuk menemukan konteks spesifik dari dokumen\n",
    "- **summary_tool**: Untuk menemukan ringkasan dokumen\n",
    "\n",
    "**Penjelasan Metadata:**\n",
    "Metadata dokumen mencakup informasi berikut:\n",
    "- **file_name**: Nama file dokumen\n",
    "- **title**: Judul dokumen\n",
    "- **sector**: Sektor yang dicakup oleh regulasi\n",
    "- **subsector**: Subsektor yang dicakup oleh regulasi\n",
    "- **regulation_type**: Jenis regulasi (misalnya, Surat Edaran OJK, Peraturan OJK)\n",
    "- **regulation_number**: Nomor regulasi\n",
    "- **effective_date**: Tanggal berlakunya regulasi\n",
    "\n",
    "----------------------------------------------\n",
    "Query: {query_str}\n",
    "Jawaban:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.storage.chat_store import SimpleChatStore\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "\n",
    "chat_store = SimpleChatStore()\n",
    "memory = ChatMemoryBuffer.from_defaults(\n",
    "    token_limit=10000,\n",
    "    chat_store=chat_store,\n",
    "    chat_store_key=\"user1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.callbacks import CallbackManager, LlamaDebugHandler\n",
    "\n",
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.core.agent.legacy.react.base import ReActAgent\n",
    "\n",
    "\n",
    "# agent = OpenAIAgent.from_tools(\n",
    "#     tools=query_engine_tools,\n",
    "#     llm=llm,\n",
    "#     verbose=True,\n",
    "#     memory=memory,\n",
    "#     system_prompt=system_prompt,\n",
    "#     callback_manager=callback_manager,\n",
    "# )\n",
    "\n",
    "agent = ReActAgent.from_tools(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    tools=query_engine_tools,\n",
    "    verbose=True,\n",
    "    system_prompt=system_prompt,\n",
    "    callback_manager=callback_manager,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is Indonesian. I need to use a tool to help me find the title of the regulation.\n",
      "Action: vector_tool\n",
      "Action Input: {'input': 'judul peraturan 7/33/PBI/2005'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Empty Response\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I cannot answer the question with the provided tools.\n",
      "Answer: Maaf, saya tidak dapat menemukan judul peraturan 7/33/PBI/2005 dengan menggunakan alat yang tersedia.\n",
      "\u001b[0m**********\n",
      "Trace: chat\n",
      "    |_llm -> 2.163959 seconds\n",
      "    |_function_call -> 1.447649 seconds\n",
      "    |_llm -> 1.065772 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "response_agent = agent.chat(message=query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Maaf, saya tidak dapat menemukan judul peraturan 7/33/PBI/2005 dengan menggunakan alat yang tersedia."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_response\n",
    "\n",
    "display_response(response=response_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "for node in response_agent.source_nodes:\n",
    "    display_source_node(node, show_source_metadata=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_store_string = chat_store.json()\n",
    "loaded_chat_store = SimpleChatStore.parse_raw(chat_store_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
