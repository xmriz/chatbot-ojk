{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **OJKGPT**\n",
    "\n",
    "This is the Jupyter Notebook for the development of the 1st version of OJKGPT for the showcase demo capabilites to wealth team program. <br>\n",
    "In this development, we use several data sources for enriching the RAG system of the chatbot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.models_definer import ModelName\n",
    "\n",
    "# storing or not\n",
    "OCR_TRESHOLD = 0.98\n",
    "TOP_K = 3\n",
    "NUM_BATCH_EVAL = 10\n",
    "STORE = True\n",
    "DELETE = True\n",
    "EVAL = True\n",
    "model_name_eval = ModelName.OPENAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LLM Models Define**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from utils.models_definer import get_llm_and_embedding\n",
    "\n",
    "# ollama/openai/azure_openai\n",
    "llm = get_llm_and_embedding(model_name=ModelName.OLLAMA)[0]\n",
    "embedding_llm = get_llm_and_embedding(model_name=ModelName.AZURE_OPENAI)[1]\n",
    "\n",
    "llm_eval = get_llm_and_embedding(model_name=model_name_eval)[0]\n",
    "\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embedding_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loading Documents**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Document Reader and Node Parser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: cmsOpenProfileFromMem failed\n",
      "\n",
      "Read 9 documents\n"
     ]
    }
   ],
   "source": [
    "from utils.documents_reader import read_documents\n",
    "from utils.node_parser import parse_nodes\n",
    "\n",
    "path = './data'\n",
    "\n",
    "if STORE:\n",
    "    docs = read_documents(path=path, ocr_treshold=OCR_TRESHOLD)\n",
    "    nodes = parse_nodes(documents=docs, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Indexing & Storing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 35 index from the collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 35/35 [00:11<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing the vector index completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing documents:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current doc id: 69df71d0-0079-4242-80fd-df48458b995d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing documents:   0%|          | 0/9 [00:33<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ReadTimeout",
     "evalue": "timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\httpx\\_transports\\default.py:69\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\httpx\\_transports\\default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\httpcore\\_sync\\http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\httpcore\\_sync\\http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    107\u001b[0m     (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m         trailing_data,\n\u001b[1;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m         http_version,\n\u001b[0;32m    116\u001b[0m         status,\n\u001b[0;32m    117\u001b[0m         reason_phrase,\n\u001b[0;32m    118\u001b[0m         headers,\n\u001b[0;32m    119\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\httpcore\\_sync\\http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\httpcore\\_sync\\http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\httpcore\\_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[1;34m(map)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[1;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mReadTimeout\u001b[0m: timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m STORE:\n\u001b[0;32m      5\u001b[0m     vector_index \u001b[38;5;241m=\u001b[39m store_vector_index(nodes\u001b[38;5;241m=\u001b[39mnodes,embed_model\u001b[38;5;241m=\u001b[39membedding_llm, delete\u001b[38;5;241m=\u001b[39mDELETE)\n\u001b[1;32m----> 6\u001b[0m     summary_index \u001b[38;5;241m=\u001b[39m \u001b[43mstore_summary_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelete\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDELETE\u001b[49m\u001b[43m,\u001b[49m\u001b[43membed_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_llm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# load\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     vector_index \u001b[38;5;241m=\u001b[39m load_vector_index()\n",
      "File \u001b[1;32md:\\Coding\\git-repo\\github\\ocbc_chatbot\\chatbot-ojk\\utils\\index_store.py:111\u001b[0m, in \u001b[0;36mstore_summary_index\u001b[1;34m(llm, embed_model, nodes, delete)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m     response_synthesizer \u001b[38;5;241m=\u001b[39m get_response_synthesizer(\n\u001b[0;32m    109\u001b[0m         response_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtree_summarize\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_async\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     )\n\u001b[1;32m--> 111\u001b[0m     summary_index \u001b[38;5;241m=\u001b[39m \u001b[43mDocumentSummaryIndex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_synthesizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_synthesizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m     summary_index\u001b[38;5;241m.\u001b[39mstorage_context\u001b[38;5;241m.\u001b[39mpersist(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStoring the summary index completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\llama_index\\core\\indices\\document_summary\\base.py:107\u001b[0m, in \u001b[0;36mDocumentSummaryIndex.__init__\u001b[1;34m(self, nodes, objects, index_struct, llm, embed_model, storage_context, response_synthesizer, summary_query, show_progress, embed_summaries, service_context, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summary_query \u001b[38;5;241m=\u001b[39m summary_query\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_summaries \u001b[38;5;241m=\u001b[39m embed_summaries\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    108\u001b[0m     nodes\u001b[38;5;241m=\u001b[39mnodes,\n\u001b[0;32m    109\u001b[0m     index_struct\u001b[38;5;241m=\u001b[39mindex_struct,\n\u001b[0;32m    110\u001b[0m     service_context\u001b[38;5;241m=\u001b[39mservice_context,\n\u001b[0;32m    111\u001b[0m     storage_context\u001b[38;5;241m=\u001b[39mstorage_context,\n\u001b[0;32m    112\u001b[0m     show_progress\u001b[38;5;241m=\u001b[39mshow_progress,\n\u001b[0;32m    113\u001b[0m     objects\u001b[38;5;241m=\u001b[39mobjects,\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    115\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\llama_index\\core\\indices\\base.py:94\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[1;34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, service_context, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_struct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m---> 94\u001b[0m     index_struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_index_from_nodes(\n\u001b[0;32m     95\u001b[0m         nodes \u001b[38;5;241m+\u001b[39m objects, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     )\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct \u001b[38;5;241m=\u001b[39m index_struct\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context\u001b[38;5;241m.\u001b[39mindex_store\u001b[38;5;241m.\u001b[39madd_index_struct(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct)\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\llama_index\\core\\indices\\base.py:216\u001b[0m, in \u001b[0;36mBaseIndex.build_index_from_nodes\u001b[1;34m(self, nodes, **build_kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build the index from nodes.\"\"\"\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_docstore\u001b[38;5;241m.\u001b[39madd_documents(nodes, allow_update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_index_from_nodes(nodes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuild_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\llama_index\\core\\indices\\document_summary\\base.py:240\u001b[0m, in \u001b[0;36mDocumentSummaryIndex._build_index_from_nodes\u001b[1;34m(self, nodes)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# first get doc_id to nodes_dict, generate a summary for each doc_id,\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# then build the index struct\u001b[39;00m\n\u001b[0;32m    239\u001b[0m index_struct \u001b[38;5;241m=\u001b[39m IndexDocumentSummary()\n\u001b[1;32m--> 240\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_nodes_to_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_progress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index_struct\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\llama_index\\core\\indices\\document_summary\\base.py:198\u001b[0m, in \u001b[0;36mDocumentSummaryIndex._add_nodes_to_index\u001b[1;34m(self, index_struct, nodes, show_progress)\u001b[0m\n\u001b[0;32m    196\u001b[0m nodes_with_scores \u001b[38;5;241m=\u001b[39m [NodeWithScore(node\u001b[38;5;241m=\u001b[39mn) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m nodes]\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# get the summary for each doc_id\u001b[39;00m\n\u001b[1;32m--> 198\u001b[0m summary_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_response_synthesizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthesize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_summary_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes_with_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m summary_response \u001b[38;5;241m=\u001b[39m cast(Response, summary_response)\n\u001b[0;32m    203\u001b[0m metadata \u001b[38;5;241m=\u001b[39m doc_id_to_nodes\u001b[38;5;241m.\u001b[39mget(doc_id, [TextNode()])[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmetadata\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[0;32m    228\u001b[0m )\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\llama_index\\core\\response_synthesizers\\base.py:241\u001b[0m, in \u001b[0;36mBaseSynthesizer.synthesize\u001b[1;34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m     query \u001b[38;5;241m=\u001b[39m QueryBundle(query_str\u001b[38;5;241m=\u001b[39mquery)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    238\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mSYNTHESIZE,\n\u001b[0;32m    239\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query\u001b[38;5;241m.\u001b[39mquery_str},\n\u001b[0;32m    240\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[1;32m--> 241\u001b[0m     response_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_response(\n\u001b[0;32m    242\u001b[0m         query_str\u001b[38;5;241m=\u001b[39mquery\u001b[38;5;241m.\u001b[39mquery_str,\n\u001b[0;32m    243\u001b[0m         text_chunks\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    244\u001b[0m             n\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mget_content(metadata_mode\u001b[38;5;241m=\u001b[39mMetadataMode\u001b[38;5;241m.\u001b[39mLLM) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m nodes\n\u001b[0;32m    245\u001b[0m         ],\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs,\n\u001b[0;32m    247\u001b[0m     )\n\u001b[0;32m    249\u001b[0m     additional_source_nodes \u001b[38;5;241m=\u001b[39m additional_source_nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[0;32m    250\u001b[0m     source_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(nodes) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(additional_source_nodes)\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[0;32m    228\u001b[0m )\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\llama_index\\core\\response_synthesizers\\tree_summarize.py:169\u001b[0m, in \u001b[0;36mTreeSummarize.get_response\u001b[1;34m(self, query_str, text_chunks, **response_kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_cls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m    170\u001b[0m             summary_template,\n\u001b[0;32m    171\u001b[0m             context_str\u001b[38;5;241m=\u001b[39mtext_chunks[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    172\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs,\n\u001b[0;32m    173\u001b[0m         )\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mstructured_predict(\n\u001b[0;32m    176\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_cls,\n\u001b[0;32m    177\u001b[0m             summary_template,\n\u001b[0;32m    178\u001b[0m             context_str\u001b[38;5;241m=\u001b[39mtext_chunks[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kwargs,\n\u001b[0;32m    180\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[0;32m    228\u001b[0m )\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\llama_index\\core\\llms\\llm.py:434\u001b[0m, in \u001b[0;36mLLM.predict\u001b[1;34m(self, prompt, **prompt_args)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mis_chat_model:\n\u001b[0;32m    433\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_messages(prompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprompt_args)\n\u001b[1;32m--> 434\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m     output \u001b[38;5;241m=\u001b[39m chat_response\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:230\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[0;32m    227\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_, bound_args\u001b[38;5;241m=\u001b[39mbound_args, instance\u001b[38;5;241m=\u001b[39minstance, parent_id\u001b[38;5;241m=\u001b[39mparent_id\n\u001b[0;32m    228\u001b[0m )\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\llama_index\\core\\llms\\callbacks.py:172\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[1;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[0;32m    164\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[0;32m    165\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m     },\n\u001b[0;32m    170\u001b[0m )\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m f(_self, messages, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    174\u001b[0m     callback_manager\u001b[38;5;241m.\u001b[39mon_event_end(\n\u001b[0;32m    175\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[0;32m    176\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mEXCEPTION: e},\n\u001b[0;32m    177\u001b[0m         event_id\u001b[38;5;241m=\u001b[39mevent_id,\n\u001b[0;32m    178\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\llama_index\\llms\\ollama\\base.py:131\u001b[0m, in \u001b[0;36mOllama.chat\u001b[1;34m(self, messages, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     payload[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mClient(timeout\u001b[38;5;241m=\u001b[39mTimeout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_timeout)) \u001b[38;5;28;01mas\u001b[39;00m client:\n\u001b[1;32m--> 131\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/api/chat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    136\u001b[0m     raw \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\httpx\\_client.py:1145\u001b[0m, in \u001b[0;36mClient.post\u001b[1;34m(self, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1126\u001b[0m     url: URLTypes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     extensions: RequestExtensions \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1139\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;124;03m    Send a `POST` request.\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m \n\u001b[0;32m   1143\u001b[0m \u001b[38;5;124;03m    **Parameters**: See `httpx.request`.\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\httpx\\_client.py:827\u001b[0m, in \u001b[0;36mClient.request\u001b[1;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[0;32m    812\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m    814\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[0;32m    815\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    816\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    825\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[0;32m    826\u001b[0m )\n\u001b[1;32m--> 827\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[0;32m    910\u001b[0m )\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\httpx\\_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1012\u001b[0m     )\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\httpx\\_transports\\default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    231\u001b[0m )\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    242\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    135\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\acer\\miniconda3\\envs\\chatbot\\lib\\site-packages\\httpx\\_transports\\default.py:86\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     85\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mReadTimeout\u001b[0m: timed out"
     ]
    }
   ],
   "source": [
    "from utils.index_store import (store_vector_index, load_vector_index, store_summary_index, load_summary_index)\n",
    "\n",
    "# store\n",
    "if STORE:\n",
    "    vector_index = store_vector_index(nodes=nodes,embed_model=embedding_llm, delete=DELETE)\n",
    "    summary_index = store_summary_index(nodes=nodes,llm=llm, delete=DELETE,embed_model=embedding_llm)\n",
    "# load\n",
    "else:\n",
    "    vector_index = load_vector_index()\n",
    "    summary_index = load_summary_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Querying**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Retriever**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.document_summary import (\n",
    "    DocumentSummaryIndexLLMRetriever\n",
    ")\n",
    "from llama_index.core.retrievers import RecursiveRetriever\n",
    "\n",
    "vector_retriever = vector_index.as_retriever(similarity_top_k=TOP_K)\n",
    "\n",
    "recursive_retriever = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever}\n",
    ")\n",
    "\n",
    "summary_retriever = DocumentSummaryIndexLLMRetriever(\n",
    "    index=summary_index,\n",
    "    choice_top_k=TOP_K,\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Query Engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core import get_response_synthesizer\n",
    "import time\n",
    "\n",
    "vector_query_engine = RetrieverQueryEngine.from_args(retriever=recursive_retriever,llm=llm)\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(response_mode=\"tree_summarize\")\n",
    "list_query_engine = RetrieverQueryEngine.from_args(retriever=summary_retriever,llm=llm_eval)\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"Apa judul peraturan 7/33/PBI/2005?\" # Pencabutan atas Peraturan Bank Indonesia Nomor 5/17/PBI/2003 tentang Persyaratan dan Tata Cara Pelaksanaan Jaminan Pemerintah terhadap Kewajiban Pembayaran Bank Perkreditan Rakyat\n",
    "b = \"Kapan surat edaran No. 15/26/DPbS mulai berlaku?\" # 1 Agustus 2013.\n",
    "c = \"Siapa nama dan jabatannya yang menandatangani surat dengan nomor 1/SEOJK.04/2013?\" # NURHAIDA, kepala eksekutif pengawas pasar modal\n",
    "d = \"Saya ingin menyelenggarakan kegiatan pasar modal berikan saya nomor surat yang membahas mengenai hal ini!\" # Peraturan Pemerintah Nomor 12 Tahun 2004\n",
    "e = \"Berapa persen jaminan moneter pada tanggal 20 Agustus 1958?\" # 7,3%\n",
    "f = \"Surat edaran nomor berapa yang mengatur bank umum syariah dan unit usaha syariah?\" # 15/26/DPbS\n",
    "g = \"Apa kepanjangan dari PAPSI?\" # Pedoman Akuntansi Perbankan Syariah Indonesia\n",
    "h = \"apa judul peraturan nomor 112/KMK.03/2001?\" # Keputusan Menteri Keuangan tentang Pemotongan Pajak Penghasil Pasal 21 atas Penghasilan berupa Uang Pesangon, Uang Tebusan Pensiun, dan Tunjangan Hari Tua atau Jaminan Hari Tua\n",
    "i = \"Saya ingin membuat sistem informasi lembaga jasa keuangan, berikan nomor regulasi dari peraturan yang membahas tentang manejemen risiko nya!\" # 4/POJK.05/2021\n",
    "j = \"Apa kepanjangan dari SWDKLLJ?\" # Sumbangan Wajib Dana Kecelakaan Lalu Lintas Jalan\n",
    "k = \"Berapa nilai SWDKLLJ mobil sedan?\" # Rp. 140.000\n",
    "l = \"Apa latar belakang dari peraturan NOMOR 4/POJK.05/2021?\" # dalam bentuk list\n",
    "m = \"Apa itu LJKNB?\" # Lembaga Jasa Keuangan Non Bank\n",
    "n = \"Apakah KMK Nomor 462/KMK.04/1998 masih berlaku\" # tidak\n",
    "o = \"Apa itu Uang Pesangon?\" # penghasilan yang dibayarkan oleh pemberi kerja kepada karyawan dengan nama dan dalam bentuk apapun sehubungan dengan berakhirnya masa kerja atau terjadi pemutusan  hubungan kerja, termasuk uang penghargaan masa kerja dan uang  ganti kerugian\n",
    "p = \"Apa itu CKPN?\" # Cadangan Kerugian Penurunan Nilai.\n",
    "q = \"Kapan, dimana, dan oleh siapa surat nomor PER- 06/BL/2012 ditetapkan?\" # Surat nomor PER-06/BL/2012 ditetapkan pada tanggal 22 November 2012 di Jakarta oleh Ketua Badan Pengawas Pasar Modal dan Lembaga Keuangan.\n",
    "r = \"Apa kepanjangan PSAK?\" # Pernyataan Standar Akuntansi Keuangan\n",
    "s = \"Apa itu 'shahibul maal'?\" # Pemilik dana pihak ketiga\n",
    "\n",
    "query_str = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Surat edaran No. 15/26/DPbS mulai berlaku pada tanggal 10 Juli 2013."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_response\n",
    "\n",
    "response_vector = vector_query_engine.query(query_str)\n",
    "display_response(response_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Surat edaran No. 15/26/DPbS mulai berlaku pada tanggal 1 Agustus 2013."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response_summary = list_query_engine.query(query_str)\n",
    "display_response(response_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# check directory exist\n",
    "if not os.path.exists(\"./json_data\"):\n",
    "    os.makedirs(\"./json_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:47<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.evaluation import (\n",
    "    generate_question_context_pairs,\n",
    "    EmbeddingQAFinetuneDataset,\n",
    ")\n",
    "if EVAL:\n",
    "    if STORE:\n",
    "        qa_dataset = generate_question_context_pairs(\n",
    "            nodes=nodes,\n",
    "            llm=llm_eval,\n",
    "            num_questions_per_chunk=2,\n",
    "        )\n",
    "        qa_dataset.save_json(\"./json_data/pg_eval_dataset.json\")\n",
    "    else:\n",
    "        qa_dataset = EmbeddingQAFinetuneDataset.from_json(\"./json_data/pg_eval_dataset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Retrieval Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"hit_rate\", \"mrr\", \"precision\", \"recall\", \"ap\", \"ndcg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>ap</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top-3 Eval</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.349402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   retrievers  hit_rate       mrr  precision  recall        ap      ndcg\n",
       "0  Top-3 Eval       0.9  0.690476        0.3     0.9  0.690476  0.349402"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.evaluator import get_retrieval_eval_df\n",
    "\n",
    "if EVAL:\n",
    "    vector_retrieval_eval_results = await get_retrieval_eval_df(name=f\"Top-{TOP_K} Eval\", metrics=metrics, retriever=vector_retriever, qa_dataset=qa_dataset)\n",
    "    display(vector_retrieval_eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Response Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import (\n",
    "    FaithfulnessEvaluator,\n",
    "    RelevancyEvaluator,\n",
    ")\n",
    "\n",
    "if EVAL:\n",
    "    # model for evaluation\n",
    "    relevancy_evaluator = RelevancyEvaluator(llm=llm_eval)\n",
    "    faithfullness_evaluator = FaithfulnessEvaluator(llm=llm_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Faithfulness Evaluator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e3900_row0_col1, #T_e3900_row0_col2 {\n",
       "  inline-size: 600px;\n",
       "  overflow-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e3900\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e3900_level0_col0\" class=\"col_heading level0 col0\" >Query</th>\n",
       "      <th id=\"T_e3900_level0_col1\" class=\"col_heading level0 col1\" >Response</th>\n",
       "      <th id=\"T_e3900_level0_col2\" class=\"col_heading level0 col2\" >Source</th>\n",
       "      <th id=\"T_e3900_level0_col3\" class=\"col_heading level0 col3\" >Evaluation Result</th>\n",
       "      <th id=\"T_e3900_level0_col4\" class=\"col_heading level0 col4\" >Reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e3900_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e3900_row0_col0\" class=\"data row0 col0\" >Kapan surat edaran No. 15/26/DPbS mulai berlaku?</td>\n",
       "      <td id=\"T_e3900_row0_col1\" class=\"data row0 col1\" >Surat edaran No. 15/26/DPbS mulai berlaku pada tanggal 10 Juli 2013.</td>\n",
       "      <td id=\"T_e3900_row0_col2\" class=\"data row0 col2\" >spesifik, Bank wajib menyampaikan rencana tindak (action plan)  \n",
       "yang akan dilakukan. \n",
       "D. \n",
       "Ketentuan mengenai estimasi penurunan nilai pembiayaan secara \n",
       "kolektif sebagaimana dimaksud dalam huruf B, merupakan acuan \n",
       "bagi Bank Syariah dalam menyusun dan menyajikan laporan \n",
       "keuangan serta menjadi acuan bagi Akuntan Publik dalam \n",
       "melakukan pemeriksaan laporan keuangan Bank Syariah. \n",
       "E. \n",
       "Hal-hal yang harus dilakukan oleh Akuntan Publik dalam \n",
       "pemeriksaan atas estimasi penurunan nilai kolektif adalah sebagai \n",
       "berikut: \n",
       "1. Dalam pelaksanaan audit, Akuntan Publik bertanggung jawab \n",
       "untuk: \n",
       "a. \n",
       "menilai kewajaran penilaian sendiri (self-assessment) yang \n",
       "dilakukan \n",
       "oleh \n",
       "manajemen \n",
       "Bank \n",
       "Syariah \n",
       "dalam \n",
       "menetapkan \n",
       "keberadaan \n",
       "kondisi \n",
       "keterbatasan \n",
       "pengalaman kerugian spesifik sebagaimana dimaksud \n",
       "dalam Lampiran Surat Edaran Bank Indonesia ini; dan \n",
       "b. \n",
       "menilai kewajaran estimasi oleh manajemen Bank Syariah \n",
       "dalam menentukan penurunan nilai pembiayaan secara \n",
       "kolektif. \n",
       "2. Apabila dalam pelak...</td>\n",
       "      <td id=\"T_e3900_row0_col3\" class=\"data row0 col3\" >Pass</td>\n",
       "      <td id=\"T_e3900_row0_col4\" class=\"data row0 col4\" >YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x215b73b6f70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9eed0_row0_col1, #T_9eed0_row0_col2 {\n",
       "  inline-size: 600px;\n",
       "  overflow-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9eed0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9eed0_level0_col0\" class=\"col_heading level0 col0\" >Query</th>\n",
       "      <th id=\"T_9eed0_level0_col1\" class=\"col_heading level0 col1\" >Response</th>\n",
       "      <th id=\"T_9eed0_level0_col2\" class=\"col_heading level0 col2\" >Source</th>\n",
       "      <th id=\"T_9eed0_level0_col3\" class=\"col_heading level0 col3\" >Evaluation Result</th>\n",
       "      <th id=\"T_9eed0_level0_col4\" class=\"col_heading level0 col4\" >Reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9eed0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9eed0_row0_col0\" class=\"data row0 col0\" >Kapan surat edaran No. 15/26/DPbS mulai berlaku?</td>\n",
       "      <td id=\"T_9eed0_row0_col1\" class=\"data row0 col1\" >Surat edaran No. 15/26/DPbS mulai berlaku pada tanggal 1 Agustus 2013.</td>\n",
       "      <td id=\"T_9eed0_row0_col2\" class=\"data row0 col2\" >C. \n",
       "Dengan diterbitkannya antara lain PSAK khusus tentang transaksi \n",
       "syariah, PSAK No. 50 (Revisi 2010) tentang Instrumen Keuangan: \n",
       "Penyajian, PSAK No. 55 (Revisi 2011) tentang Instrumen Keuangan: \n",
       "Pengakuan dan Pengukuran, dan PSAK No. 60 tentang Instrumen \n",
       "Keuangan: Pengungkapan, serta PSAK No.48 (Revisi 2009) tentang \n",
       "Penurunan Nilai Aset maka perlu dilakukan penyesuaian atas \n",
       "PAPSI 2003 menjadi PAPSI 2013 sebagaimana dimaksud pada \n",
       "Lampiran yang merupakan bagian tidak terpisahkan dari Surat \n",
       "Edaran Bank Indonesia ini. \n",
       "D. \n",
       "PAPSI \n",
       "2013 \n",
       "merupakan \n",
       "pedoman \n",
       "dalam \n",
       "penyusunan \n",
       "dan \n",
       "penyajian laporan keuangan Bank Syariah. Untuk hal-hal yang \n",
       "tidak diatur dalam PAPSI 2013 tetap berpedoman kepada PSAK \n",
       "yang berlaku beserta pedoman pelaksanaannya sepanjang tidak \n",
       "bertentangan dengan prinsip syariah. \n",
       "II. \n",
       "PENGAKUAN PENDAPATAN DALAM TRANSAKSI JUAL BELI  \n",
       "A. \n",
       "Sesuai dengan Fatwa Dewan Syariah Nasional Nomor: 84/DSN-\n",
       "MUI/XII/2012 \n",
       "tanggal \n",
       "21 \n",
       "Desember \n",
       "2012 \n",
       "tentang \n",
       "Metode \n",
       "Pengakuan Pen...</td>\n",
       "      <td id=\"T_9eed0_row0_col3\" class=\"data row0 col3\" >Pass</td>\n",
       "      <td id=\"T_9eed0_row0_col4\" class=\"data row0 col4\" >YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x215b76598e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.evaluator import get_response_eval_df\n",
    "\n",
    "if EVAL:\n",
    "    vector_faithfullness_eval_result = faithfullness_evaluator.evaluate_response(response=response_vector, query=query_str)\n",
    "    summary_faithfullness_eval_result = faithfullness_evaluator.evaluate_response(response=response_summary, query=query_str)\n",
    "    display(get_response_eval_df(query=query_str, response=response_vector, eval_result=vector_faithfullness_eval_result))\n",
    "    display(get_response_eval_df(query=query_str, response=response_summary, eval_result=summary_faithfullness_eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Source Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e71d1_row0_col0, #T_e71d1_row1_col0, #T_e71d1_row2_col0 {\n",
       "  inline-size: 600px;\n",
       "  overflow-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e71d1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e71d1_level0_col0\" class=\"col_heading level0 col0\" >Source</th>\n",
       "      <th id=\"T_e71d1_level0_col1\" class=\"col_heading level0 col1\" >Metadata</th>\n",
       "      <th id=\"T_e71d1_level0_col2\" class=\"col_heading level0 col2\" >Eval Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e71d1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e71d1_row0_col0\" class=\"data row0 col0\" >spesifik, Bank wajib menyampaikan rencana tindak (action plan)  \n",
       "yang akan dilakukan. \n",
       "D. \n",
       "Ketentuan mengenai estimasi penurunan nilai pembiayaan secara \n",
       "kolektif sebagaimana dimaksud dalam huruf B, merupakan acuan \n",
       "bagi Bank Syariah dalam menyusun dan menyajikan laporan \n",
       "keuangan serta menjadi acuan bagi Akuntan Publik dalam \n",
       "melakukan pemeriksaan laporan keuangan Bank Syariah. \n",
       "E. \n",
       "Hal-hal yang harus dilakukan oleh Akuntan Publik dalam \n",
       "pemeriksaan atas estimasi penurunan nilai kolektif adalah sebagai \n",
       "berikut: \n",
       "1. Dalam pelaksanaan audit, Akuntan Publik bertanggung jawab \n",
       "untuk: \n",
       "a. \n",
       "menilai kewajaran penilaian sendiri (self-assessment) yang \n",
       "dilakukan \n",
       "oleh \n",
       "manajemen \n",
       "Bank \n",
       "Syariah \n",
       "dalam \n",
       "menetapkan \n",
       "keberadaan \n",
       "kondisi \n",
       "keterbatasan \n",
       "pengalaman kerugian spesifik sebagaimana dimaksud \n",
       "dalam Lampiran Surat Edaran Bank Indonesia ini; dan \n",
       "b. \n",
       "menilai kewajaran estimasi oleh manajemen Bank Syariah \n",
       "dalam menentukan penurunan nilai pembiayaan secara \n",
       "kolektif. \n",
       "2. Apabila dalam pelaksanaan audit, Akuntan Publik menemukan \n",
       "bahwa Bank Syariah tidak berada dalam kondisi keterbatasan \n",
       "pengalaman kerugian spesifik namun menerapkan estimasi \n",
       "penurunan nilai pembiayaan secara kolektif maka Bank \n",
       "Syariah dinilai tidak menerapkan PSAK 55 beserta pedoman \n",
       "pelaksanaannya dan melanggar Surat Edaran Bank Indonesia \n",
       "ini. \n",
       "3. Temuan Akuntan Publik sebagaimana dimaksud dalam angka \n",
       "2 harus diungkapkan oleh Akuntan Publik dalam laporan hasil \n",
       "audit dan Surat Komentar (Management Letter) dan wajib \n",
       "disampaikan kepada Bank Indonesia sebagaimana diatur \n",
       "dalam ketentuan Bank Indonesia yang mengatur mengenai \n",
       "transparansi kondisi keuangan bank. \n",
       "F. Dalam … \n",
       "\n",
       "\n",
       "F. \n",
       "Dalam rangka memberikan informasi yang lebih transparan kepada \n",
       "masyarakat dan pengguna laporan keuangan Bank, Bank Syariah \n",
       "yang menerapkan estimasi penurunan nilai pembiayaan secara \n",
       "kolektif wajib mengungkapkan informasi tersebut dalam Catatan \n",
       "atas Laporan Keuangan dalam Laporan Tahunan sebagaimana \n",
       "diatur dalam Surat Edaran Bank Indonesia mengenai laporan \n",
       "tahunan bank umum. \n",
       "VI. KETENTUAN PENUTUP \n",
       "Dengan berlakunya Surat Edaran Bank Indonesia ini, Surat Edaran \n",
       "Bank Indonesia Nomor 5/26/BPS tanggal 27 Oktober 2003 perihal \n",
       "Pelaksanaan \n",
       "Pedoman \n",
       "Akuntansi \n",
       "Perbankan \n",
       "Syariah \n",
       "Indonesia \n",
       "dinyatakan tidak berlaku bagi Bank Umum Syariah dan Unit Usaha \n",
       "Syariah. \n",
       " \n",
       "Surat  Edaran  Bank  Indonesia  ini  mulai  berlaku  pada  tanggal 1 \n",
       "Agustus 2013.   \n",
       " \n",
       "Agar setiap orang mengetahuinya, memerintahkan pengumuman \n",
       "Surat Edaran Bank Indonesia ini dengan penempatannya dalam Berita \n",
       "Negara Republik Indonesia. \n",
       " \n",
       "Demikian agar Saudara maklum. \n",
       " \n",
       "BANK INDONESIA, \n",
       " \n",
       " \n",
       " \n",
       "HALIM ALAMSYAH  \n",
       "DEPUTI GUBERNUR \n",
       " \n",
       "DPbS</td>\n",
       "      <td id=\"T_e71d1_row0_col1\" class=\"data row0 col1\" >{'file_name': 'ojk-sebi-15_26_dpbs-10072013-sebi_perihal_pelaksanaan_pedoman_akuntansi_perbankan_syariah_indonesia_sebi_26_pdf.pdf', 'title': 'Surat Edaran Bank Indonesia perihal Pelaksanaan Pedoman Akuntansi Perbankan Syariah Indonesia', 'sector': 'Perbankan', 'subsector': 'Perbankan Syariah', 'regulation_type': 'SEBI', 'regulation_number': '15/26/DPbS', 'effective_date': '10 Juli 2013', 'retrieval_score': 0.921248197555542}</td>\n",
       "      <td id=\"T_e71d1_row0_col2\" class=\"data row0 col2\" >Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e71d1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e71d1_row1_col0\" class=\"data row1 col0\" >juta rupiah) sampai dengan Rp 100.000.000,00 (seratus juta \n",
       "rupiah) sebesar 10% (sepuluh persen);  \n",
       " \n",
       "  \n",
       "d.  penghasilan bruto di atas Rp 100.000.000,00 (seratus juta \n",
       "rupiah) sampai dengan Rp 200.000.000,00 (dua ratus juta \n",
       "rupiah) sebesar 15% (lima belas persen);  \n",
       " \n",
       "  \n",
       "e.  penghasilan bruto di atas Rp 200.000.000,00 (dua ratus juta \n",
       "rupiah) sebesar 25% (dua puliuh lima belas persen); \n",
       " \n",
       " \n",
       " \n",
       "Pasal  3 \n",
       "Pada saat Keputusan Menteri Keuangan ini mulai berlaku, Keputusan \n",
       "Menteri Keuangan Nomor 462/KMK.04/1998 dinyatakan tidak berlaku.\n",
       "Pasal  4 \n",
       "Keputusan ini mulai berlaku tanggal 1 Januari 2001. \n",
       "Agar setiap orang mengetahuinya, memerintahkan pengumuman \n",
       "Keputusan Menteri Keuangan ini dengan penempatannya dalam Berita \n",
       "Negara Republik Indonesia. \n",
       " \n",
       " \n",
       "Ditetapkan di Jakarta  \n",
       "pada tanggal 6 Maret 2001  \n",
       "MENTERI \n",
       "KEUANGAN \n",
       "REPUBLIK \n",
       "INDONESIA \n",
       " \n",
       "PRIJADI PRAPTOSUHARDJO</td>\n",
       "      <td id=\"T_e71d1_row1_col1\" class=\"data row1 col1\" >{'file_name': 'ojk-peraturan_keputusan_mentri-112_kmk_03_2001-06032001-kmk_nomor_112_kmk_03_2001_112_kmk_03_2001_pdf.pdf', 'title': 'Keputusan Menteri Keuangan tentang Pemotongan Pajak Penghasil Pasal 21 atas Penghasilan berupa Uang Pesangon, Uang Tebusan Pensiun, dan Tunjangan Hari Tua atau Jaminan Hari Tua', 'sector': 'IKNB', 'subsector': 'Dana Pensiun', 'regulation_type': 'Peraturan/Keputusan Mentri', 'regulation_number': '112/KMK.03/2001', 'effective_date': '6 Maret 2001', 'retrieval_score': 0.9134289622306824}</td>\n",
       "      <td id=\"T_e71d1_row1_col2\" class=\"data row1 col2\" >Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e71d1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e71d1_row2_col0\" class=\"data row2 col0\" >No. 15/26/DPbS  \n",
       " \n",
       " \n",
       " \n",
       "     Jakarta, 10  Juli  2013    \n",
       " \n",
       " \n",
       "S U R A T    E D A R A N \n",
       " \n",
       "Kepada \n",
       "SEMUA BANK UMUM SYARIAH DAN UNIT USAHA SYARIAH  \n",
       "DI INDONESIA \n",
       " \n",
       "Perihal :  \n",
       "Pelaksanaan Pedoman Akuntansi Perbankan Syariah \n",
       "Indonesia. \n",
       " \n",
       "     \n",
       "Sehubungan \n",
       "dengan \n",
       "Peraturan \n",
       "Bank \n",
       "Indonesia \n",
       "Nomor \n",
       "14/14/PBI/2012 tentang Transparansi dan Publikasi Laporan Bank \n",
       "(Lembaran Negara Republik Indonesia Tahun 2012 Nomor 199, Tambahan \n",
       "Lembaran Negara Republik Indonesia Tahun 2012 Nomor 5353), perlu \n",
       "diatur ketentuan mengenai pelaksanaan pedoman akuntansi perbankan \n",
       "syariah Indonesia dalam Surat Edaran Bank Indonesia sebagai berikut:  \n",
       "I. \n",
       "KETENTUAN UMUM \n",
       "A. \n",
       "Dalam rangka peningkatan transparansi kondisi keuangan bagi \n",
       "Bank Umum Syariah dan Unit Usaha Syariah, selanjutnya disebut \n",
       "Bank Syariah, dan penyusunan laporan keuangan yang relevan, \n",
       "komprehensif, andal dan dapat diperbandingkan, Bank Syariah \n",
       "menyusun \n",
       "dan \n",
       "menyajikan \n",
       "laporan \n",
       "keuangan \n",
       "berdasarkan \n",
       "Pernyataan Standar Akuntansi Keuangan (PSAK) yang relevan bagi \n",
       "Bank Syariah, Pedoman Akuntansi Perbankan Syariah Indonesia \n",
       "(PAPSI), dan ketentuan lain yang ditetapkan oleh Bank Indonesia. \n",
       "B. \n",
       "PAPSI merupakan petunjuk pelaksanaan yang berisi penjabaran \n",
       "lebih \n",
       "lanjut \n",
       "dari \n",
       "beberapa \n",
       "Pernyataan \n",
       "Standar \n",
       "Akuntansi \n",
       "Keuangan (PSAK) yang relevan bagi industri perbankan syariah. \n",
       "C. Dengan …</td>\n",
       "      <td id=\"T_e71d1_row2_col1\" class=\"data row2 col1\" >{'file_name': 'ojk-sebi-15_26_dpbs-10072013-sebi_perihal_pelaksanaan_pedoman_akuntansi_perbankan_syariah_indonesia_sebi_26_pdf.pdf', 'title': 'Surat Edaran Bank Indonesia perihal Pelaksanaan Pedoman Akuntansi Perbankan Syariah Indonesia', 'sector': 'Perbankan', 'subsector': 'Perbankan Syariah', 'regulation_type': 'SEBI', 'regulation_number': '15/26/DPbS', 'effective_date': '10 Juli 2013', 'retrieval_score': 0.9121730327606201}</td>\n",
       "      <td id=\"T_e71d1_row2_col2\" class=\"data row2 col2\" >Pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x215b7718df0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.evaluator import get_response_eval_sources_df\n",
    "\n",
    "if EVAL:\n",
    "    relevancy_eval_sources = get_response_eval_sources_df(query=query_str, response=response_vector, evaluator=faithfullness_evaluator)\n",
    "    display(relevancy_eval_sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Relevancy Evaluator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_76913_row0_col1, #T_76913_row0_col2 {\n",
       "  inline-size: 600px;\n",
       "  overflow-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_76913\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_76913_level0_col0\" class=\"col_heading level0 col0\" >Query</th>\n",
       "      <th id=\"T_76913_level0_col1\" class=\"col_heading level0 col1\" >Response</th>\n",
       "      <th id=\"T_76913_level0_col2\" class=\"col_heading level0 col2\" >Source</th>\n",
       "      <th id=\"T_76913_level0_col3\" class=\"col_heading level0 col3\" >Evaluation Result</th>\n",
       "      <th id=\"T_76913_level0_col4\" class=\"col_heading level0 col4\" >Reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_76913_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_76913_row0_col0\" class=\"data row0 col0\" >Kapan surat edaran No. 15/26/DPbS mulai berlaku?</td>\n",
       "      <td id=\"T_76913_row0_col1\" class=\"data row0 col1\" >Surat edaran No. 15/26/DPbS mulai berlaku pada tanggal 10 Juli 2013.</td>\n",
       "      <td id=\"T_76913_row0_col2\" class=\"data row0 col2\" >spesifik, Bank wajib menyampaikan rencana tindak (action plan)  \n",
       "yang akan dilakukan. \n",
       "D. \n",
       "Ketentuan mengenai estimasi penurunan nilai pembiayaan secara \n",
       "kolektif sebagaimana dimaksud dalam huruf B, merupakan acuan \n",
       "bagi Bank Syariah dalam menyusun dan menyajikan laporan \n",
       "keuangan serta menjadi acuan bagi Akuntan Publik dalam \n",
       "melakukan pemeriksaan laporan keuangan Bank Syariah. \n",
       "E. \n",
       "Hal-hal yang harus dilakukan oleh Akuntan Publik dalam \n",
       "pemeriksaan atas estimasi penurunan nilai kolektif adalah sebagai \n",
       "berikut: \n",
       "1. Dalam pelaksanaan audit, Akuntan Publik bertanggung jawab \n",
       "untuk: \n",
       "a. \n",
       "menilai kewajaran penilaian sendiri (self-assessment) yang \n",
       "dilakukan \n",
       "oleh \n",
       "manajemen \n",
       "Bank \n",
       "Syariah \n",
       "dalam \n",
       "menetapkan \n",
       "keberadaan \n",
       "kondisi \n",
       "keterbatasan \n",
       "pengalaman kerugian spesifik sebagaimana dimaksud \n",
       "dalam Lampiran Surat Edaran Bank Indonesia ini; dan \n",
       "b. \n",
       "menilai kewajaran estimasi oleh manajemen Bank Syariah \n",
       "dalam menentukan penurunan nilai pembiayaan secara \n",
       "kolektif. \n",
       "2. Apabila dalam pelak...</td>\n",
       "      <td id=\"T_76913_row0_col3\" class=\"data row0 col3\" >Pass</td>\n",
       "      <td id=\"T_76913_row0_col4\" class=\"data row0 col4\" >YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x215966898b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if EVAL:\n",
    "    relevancy_eval_result = relevancy_evaluator.evaluate_response(\n",
    "        query=query_str, response=response_vector\n",
    "    )\n",
    "\n",
    "    display(get_response_eval_df(query=query_str, response=response_vector, eval_result=relevancy_eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Source Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c81ef_row0_col0, #T_c81ef_row1_col0, #T_c81ef_row2_col0 {\n",
       "  inline-size: 600px;\n",
       "  overflow-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c81ef\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c81ef_level0_col0\" class=\"col_heading level0 col0\" >Source</th>\n",
       "      <th id=\"T_c81ef_level0_col1\" class=\"col_heading level0 col1\" >Metadata</th>\n",
       "      <th id=\"T_c81ef_level0_col2\" class=\"col_heading level0 col2\" >Eval Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c81ef_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c81ef_row0_col0\" class=\"data row0 col0\" >spesifik, Bank wajib menyampaikan rencana tindak (action plan)  \n",
       "yang akan dilakukan. \n",
       "D. \n",
       "Ketentuan mengenai estimasi penurunan nilai pembiayaan secara \n",
       "kolektif sebagaimana dimaksud dalam huruf B, merupakan acuan \n",
       "bagi Bank Syariah dalam menyusun dan menyajikan laporan \n",
       "keuangan serta menjadi acuan bagi Akuntan Publik dalam \n",
       "melakukan pemeriksaan laporan keuangan Bank Syariah. \n",
       "E. \n",
       "Hal-hal yang harus dilakukan oleh Akuntan Publik dalam \n",
       "pemeriksaan atas estimasi penurunan nilai kolektif adalah sebagai \n",
       "berikut: \n",
       "1. Dalam pelaksanaan audit, Akuntan Publik bertanggung jawab \n",
       "untuk: \n",
       "a. \n",
       "menilai kewajaran penilaian sendiri (self-assessment) yang \n",
       "dilakukan \n",
       "oleh \n",
       "manajemen \n",
       "Bank \n",
       "Syariah \n",
       "dalam \n",
       "menetapkan \n",
       "keberadaan \n",
       "kondisi \n",
       "keterbatasan \n",
       "pengalaman kerugian spesifik sebagaimana dimaksud \n",
       "dalam Lampiran Surat Edaran Bank Indonesia ini; dan \n",
       "b. \n",
       "menilai kewajaran estimasi oleh manajemen Bank Syariah \n",
       "dalam menentukan penurunan nilai pembiayaan secara \n",
       "kolektif. \n",
       "2. Apabila dalam pelaksanaan audit, Akuntan Publik menemukan \n",
       "bahwa Bank Syariah tidak berada dalam kondisi keterbatasan \n",
       "pengalaman kerugian spesifik namun menerapkan estimasi \n",
       "penurunan nilai pembiayaan secara kolektif maka Bank \n",
       "Syariah dinilai tidak menerapkan PSAK 55 beserta pedoman \n",
       "pelaksanaannya dan melanggar Surat Edaran Bank Indonesia \n",
       "ini. \n",
       "3. Temuan Akuntan Publik sebagaimana dimaksud dalam angka \n",
       "2 harus diungkapkan oleh Akuntan Publik dalam laporan hasil \n",
       "audit dan Surat Komentar (Management Letter) dan wajib \n",
       "disampaikan kepada Bank Indonesia sebagaimana diatur \n",
       "dalam ketentuan Bank Indonesia yang mengatur mengenai \n",
       "transparansi kondisi keuangan bank. \n",
       "F. Dalam … \n",
       "\n",
       "\n",
       "F. \n",
       "Dalam rangka memberikan informasi yang lebih transparan kepada \n",
       "masyarakat dan pengguna laporan keuangan Bank, Bank Syariah \n",
       "yang menerapkan estimasi penurunan nilai pembiayaan secara \n",
       "kolektif wajib mengungkapkan informasi tersebut dalam Catatan \n",
       "atas Laporan Keuangan dalam Laporan Tahunan sebagaimana \n",
       "diatur dalam Surat Edaran Bank Indonesia mengenai laporan \n",
       "tahunan bank umum. \n",
       "VI. KETENTUAN PENUTUP \n",
       "Dengan berlakunya Surat Edaran Bank Indonesia ini, Surat Edaran \n",
       "Bank Indonesia Nomor 5/26/BPS tanggal 27 Oktober 2003 perihal \n",
       "Pelaksanaan \n",
       "Pedoman \n",
       "Akuntansi \n",
       "Perbankan \n",
       "Syariah \n",
       "Indonesia \n",
       "dinyatakan tidak berlaku bagi Bank Umum Syariah dan Unit Usaha \n",
       "Syariah. \n",
       " \n",
       "Surat  Edaran  Bank  Indonesia  ini  mulai  berlaku  pada  tanggal 1 \n",
       "Agustus 2013.   \n",
       " \n",
       "Agar setiap orang mengetahuinya, memerintahkan pengumuman \n",
       "Surat Edaran Bank Indonesia ini dengan penempatannya dalam Berita \n",
       "Negara Republik Indonesia. \n",
       " \n",
       "Demikian agar Saudara maklum. \n",
       " \n",
       "BANK INDONESIA, \n",
       " \n",
       " \n",
       " \n",
       "HALIM ALAMSYAH  \n",
       "DEPUTI GUBERNUR \n",
       " \n",
       "DPbS</td>\n",
       "      <td id=\"T_c81ef_row0_col1\" class=\"data row0 col1\" >{'file_name': 'ojk-sebi-15_26_dpbs-10072013-sebi_perihal_pelaksanaan_pedoman_akuntansi_perbankan_syariah_indonesia_sebi_26_pdf.pdf', 'title': 'Surat Edaran Bank Indonesia perihal Pelaksanaan Pedoman Akuntansi Perbankan Syariah Indonesia', 'sector': 'Perbankan', 'subsector': 'Perbankan Syariah', 'regulation_type': 'SEBI', 'regulation_number': '15/26/DPbS', 'effective_date': '10 Juli 2013', 'retrieval_score': 0.921248197555542}</td>\n",
       "      <td id=\"T_c81ef_row0_col2\" class=\"data row0 col2\" >Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c81ef_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c81ef_row1_col0\" class=\"data row1 col0\" >juta rupiah) sampai dengan Rp 100.000.000,00 (seratus juta \n",
       "rupiah) sebesar 10% (sepuluh persen);  \n",
       " \n",
       "  \n",
       "d.  penghasilan bruto di atas Rp 100.000.000,00 (seratus juta \n",
       "rupiah) sampai dengan Rp 200.000.000,00 (dua ratus juta \n",
       "rupiah) sebesar 15% (lima belas persen);  \n",
       " \n",
       "  \n",
       "e.  penghasilan bruto di atas Rp 200.000.000,00 (dua ratus juta \n",
       "rupiah) sebesar 25% (dua puliuh lima belas persen); \n",
       " \n",
       " \n",
       " \n",
       "Pasal  3 \n",
       "Pada saat Keputusan Menteri Keuangan ini mulai berlaku, Keputusan \n",
       "Menteri Keuangan Nomor 462/KMK.04/1998 dinyatakan tidak berlaku.\n",
       "Pasal  4 \n",
       "Keputusan ini mulai berlaku tanggal 1 Januari 2001. \n",
       "Agar setiap orang mengetahuinya, memerintahkan pengumuman \n",
       "Keputusan Menteri Keuangan ini dengan penempatannya dalam Berita \n",
       "Negara Republik Indonesia. \n",
       " \n",
       " \n",
       "Ditetapkan di Jakarta  \n",
       "pada tanggal 6 Maret 2001  \n",
       "MENTERI \n",
       "KEUANGAN \n",
       "REPUBLIK \n",
       "INDONESIA \n",
       " \n",
       "PRIJADI PRAPTOSUHARDJO</td>\n",
       "      <td id=\"T_c81ef_row1_col1\" class=\"data row1 col1\" >{'file_name': 'ojk-peraturan_keputusan_mentri-112_kmk_03_2001-06032001-kmk_nomor_112_kmk_03_2001_112_kmk_03_2001_pdf.pdf', 'title': 'Keputusan Menteri Keuangan tentang Pemotongan Pajak Penghasil Pasal 21 atas Penghasilan berupa Uang Pesangon, Uang Tebusan Pensiun, dan Tunjangan Hari Tua atau Jaminan Hari Tua', 'sector': 'IKNB', 'subsector': 'Dana Pensiun', 'regulation_type': 'Peraturan/Keputusan Mentri', 'regulation_number': '112/KMK.03/2001', 'effective_date': '6 Maret 2001', 'retrieval_score': 0.9134289622306824}</td>\n",
       "      <td id=\"T_c81ef_row1_col2\" class=\"data row1 col2\" >Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c81ef_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c81ef_row2_col0\" class=\"data row2 col0\" >No. 15/26/DPbS  \n",
       " \n",
       " \n",
       " \n",
       "     Jakarta, 10  Juli  2013    \n",
       " \n",
       " \n",
       "S U R A T    E D A R A N \n",
       " \n",
       "Kepada \n",
       "SEMUA BANK UMUM SYARIAH DAN UNIT USAHA SYARIAH  \n",
       "DI INDONESIA \n",
       " \n",
       "Perihal :  \n",
       "Pelaksanaan Pedoman Akuntansi Perbankan Syariah \n",
       "Indonesia. \n",
       " \n",
       "     \n",
       "Sehubungan \n",
       "dengan \n",
       "Peraturan \n",
       "Bank \n",
       "Indonesia \n",
       "Nomor \n",
       "14/14/PBI/2012 tentang Transparansi dan Publikasi Laporan Bank \n",
       "(Lembaran Negara Republik Indonesia Tahun 2012 Nomor 199, Tambahan \n",
       "Lembaran Negara Republik Indonesia Tahun 2012 Nomor 5353), perlu \n",
       "diatur ketentuan mengenai pelaksanaan pedoman akuntansi perbankan \n",
       "syariah Indonesia dalam Surat Edaran Bank Indonesia sebagai berikut:  \n",
       "I. \n",
       "KETENTUAN UMUM \n",
       "A. \n",
       "Dalam rangka peningkatan transparansi kondisi keuangan bagi \n",
       "Bank Umum Syariah dan Unit Usaha Syariah, selanjutnya disebut \n",
       "Bank Syariah, dan penyusunan laporan keuangan yang relevan, \n",
       "komprehensif, andal dan dapat diperbandingkan, Bank Syariah \n",
       "menyusun \n",
       "dan \n",
       "menyajikan \n",
       "laporan \n",
       "keuangan \n",
       "berdasarkan \n",
       "Pernyataan Standar Akuntansi Keuangan (PSAK) yang relevan bagi \n",
       "Bank Syariah, Pedoman Akuntansi Perbankan Syariah Indonesia \n",
       "(PAPSI), dan ketentuan lain yang ditetapkan oleh Bank Indonesia. \n",
       "B. \n",
       "PAPSI merupakan petunjuk pelaksanaan yang berisi penjabaran \n",
       "lebih \n",
       "lanjut \n",
       "dari \n",
       "beberapa \n",
       "Pernyataan \n",
       "Standar \n",
       "Akuntansi \n",
       "Keuangan (PSAK) yang relevan bagi industri perbankan syariah. \n",
       "C. Dengan …</td>\n",
       "      <td id=\"T_c81ef_row2_col1\" class=\"data row2 col1\" >{'file_name': 'ojk-sebi-15_26_dpbs-10072013-sebi_perihal_pelaksanaan_pedoman_akuntansi_perbankan_syariah_indonesia_sebi_26_pdf.pdf', 'title': 'Surat Edaran Bank Indonesia perihal Pelaksanaan Pedoman Akuntansi Perbankan Syariah Indonesia', 'sector': 'Perbankan', 'subsector': 'Perbankan Syariah', 'regulation_type': 'SEBI', 'regulation_number': '15/26/DPbS', 'effective_date': '10 Juli 2013', 'retrieval_score': 0.9121730327606201}</td>\n",
       "      <td id=\"T_c81ef_row2_col2\" class=\"data row2 col2\" >Pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x215b7718220>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.evaluator import get_response_eval_sources_df\n",
    "\n",
    "if EVAL:\n",
    "    relevancy_eval_sources = get_response_eval_sources_df(query=query_str, response=response_vector, evaluator=relevancy_evaluator)\n",
    "    display(relevancy_eval_sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Batch Evaluator (Faithfulness, Relevancy, Correctness)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.get_embedding in 0.3267883313199005 seconds as it raised APITimeoutError: Request timed out..\n",
      "Retrying llama_index.embeddings.openai.base.get_embedding in 0.3267883313199005 seconds as it raised APITimeoutError: Request timed out..\n",
      "Retrying llama_index.embeddings.openai.base.get_embedding in 0.3267883313199005 seconds as it raised APITimeoutError: Request timed out..\n",
      "Retrying llama_index.embeddings.openai.base.get_embedding in 0.3267883313199005 seconds as it raised APITimeoutError: Request timed out..\n",
      "Retrying llama_index.embeddings.openai.base.get_embedding in 0.3267883313199005 seconds as it raised APITimeoutError: Request timed out..\n",
      "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.get_embedding in 1.8345369540805743 seconds as it raised APITimeoutError: Request timed out..\n",
      "Retrying llama_index.embeddings.openai.base.get_embedding in 1.8345369540805743 seconds as it raised APITimeoutError: Request timed out..\n",
      "Retrying llama_index.embeddings.openai.base.get_embedding in 1.8345369540805743 seconds as it raised APITimeoutError: Request timed out..\n",
      "Retrying llama_index.embeddings.openai.base.get_embedding in 1.8345369540805743 seconds as it raised APITimeoutError: Request timed out..\n",
      "Retrying llama_index.embeddings.openai.base.get_embedding in 1.8345369540805743 seconds as it raised APITimeoutError: Request timed out..\n",
      "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.get_embedding in 0.43314214282332897 seconds as it raised APITimeoutError: Request timed out..\n",
      "Retrying llama_index.embeddings.openai.base.get_embedding in 0.43314214282332897 seconds as it raised APITimeoutError: Request timed out..\n",
      "Retrying llama_index.embeddings.openai.base.get_embedding in 0.43314214282332897 seconds as it raised APITimeoutError: Request timed out..\n",
      "Retrying llama_index.embeddings.openai.base.get_embedding in 0.43314214282332897 seconds as it raised APITimeoutError: Request timed out..\n",
      "Retrying llama_index.embeddings.openai.base.get_embedding in 0.43314214282332897 seconds as it raised APITimeoutError: Request timed out..\n",
      "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.get_embedding in 0.9794263560117576 seconds as it raised APITimeoutError: Request timed out..\n",
      "Retrying llama_index.embeddings.openai.base.get_embedding in 0.9794263560117576 seconds as it raised APITimeoutError: Request timed out..\n",
      "Retrying llama_index.embeddings.openai.base.get_embedding in 0.9794263560117576 seconds as it raised APITimeoutError: Request timed out..\n",
      "Retrying llama_index.embeddings.openai.base.get_embedding in 0.9794263560117576 seconds as it raised APITimeoutError: Request timed out..\n",
      "Retrying llama_index.embeddings.openai.base.get_embedding in 0.9794263560117576 seconds as it raised APITimeoutError: Request timed out..\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.3443581010271157 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58723, Requested 1524. Please try again in 247ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.3443581010271157 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58723, Requested 1524. Please try again in 247ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.3443581010271157 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58723, Requested 1524. Please try again in 247ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.3443581010271157 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58723, Requested 1524. Please try again in 247ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.3443581010271157 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58723, Requested 1524. Please try again in 247ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.8351335234524011 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58666, Requested 1595. Please try again in 261ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.8351335234524011 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58666, Requested 1595. Please try again in 261ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.8351335234524011 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58666, Requested 1595. Please try again in 261ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.8351335234524011 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58666, Requested 1595. Please try again in 261ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.8351335234524011 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58666, Requested 1595. Please try again in 261ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.5656920001977365 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58613, Requested 1611. Please try again in 224ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.5656920001977365 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58613, Requested 1611. Please try again in 224ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.5656920001977365 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58613, Requested 1611. Please try again in 224ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.5656920001977365 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58613, Requested 1611. Please try again in 224ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.5656920001977365 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58613, Requested 1611. Please try again in 224ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.38276359874156896 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58580, Requested 1685. Please try again in 265ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.38276359874156896 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58580, Requested 1685. Please try again in 265ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.38276359874156896 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58580, Requested 1685. Please try again in 265ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.38276359874156896 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58580, Requested 1685. Please try again in 265ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.38276359874156896 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58580, Requested 1685. Please try again in 265ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.15440995173214678 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58558, Requested 1694. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.15440995173214678 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58558, Requested 1694. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.15440995173214678 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58558, Requested 1694. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.15440995173214678 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58558, Requested 1694. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.15440995173214678 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 58558, Requested 1694. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.39265079901727074 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59674, Requested 1688. Please try again in 1.362s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.39265079901727074 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59674, Requested 1688. Please try again in 1.362s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.39265079901727074 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59674, Requested 1688. Please try again in 1.362s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.39265079901727074 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59674, Requested 1688. Please try again in 1.362s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.39265079901727074 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59674, Requested 1688. Please try again in 1.362s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.8178789666588888 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59826, Requested 1853. Please try again in 1.679s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.8178789666588888 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59826, Requested 1853. Please try again in 1.679s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.8178789666588888 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59826, Requested 1853. Please try again in 1.679s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.8178789666588888 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59826, Requested 1853. Please try again in 1.679s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.8178789666588888 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59826, Requested 1853. Please try again in 1.679s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.08222206137015786 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59659, Requested 1611. Please try again in 1.27s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.08222206137015786 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59659, Requested 1611. Please try again in 1.27s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.08222206137015786 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59659, Requested 1611. Please try again in 1.27s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.08222206137015786 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59659, Requested 1611. Please try again in 1.27s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.08222206137015786 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59659, Requested 1611. Please try again in 1.27s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 1.3425708620659444 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59602, Requested 1688. Please try again in 1.29s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 1.3425708620659444 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59602, Requested 1688. Please try again in 1.29s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 1.3425708620659444 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59602, Requested 1688. Please try again in 1.29s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 1.3425708620659444 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59602, Requested 1688. Please try again in 1.29s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 1.3425708620659444 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59602, Requested 1688. Please try again in 1.29s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.38079817710795183 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59598, Requested 1685. Please try again in 1.283s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.38079817710795183 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59598, Requested 1685. Please try again in 1.283s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.38079817710795183 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59598, Requested 1685. Please try again in 1.283s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.38079817710795183 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59598, Requested 1685. Please try again in 1.283s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.38079817710795183 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59598, Requested 1685. Please try again in 1.283s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.2773278471117877 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59717, Requested 2034. Please try again in 1.751s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.2773278471117877 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59717, Requested 2034. Please try again in 1.751s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.2773278471117877 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59717, Requested 2034. Please try again in 1.751s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.2773278471117877 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59717, Requested 2034. Please try again in 1.751s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.2773278471117877 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59717, Requested 2034. Please try again in 1.751s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 1.5011846691551989 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59768, Requested 1853. Please try again in 1.621s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 1.5011846691551989 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59768, Requested 1853. Please try again in 1.621s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 1.5011846691551989 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59768, Requested 1853. Please try again in 1.621s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 1.5011846691551989 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59768, Requested 1853. Please try again in 1.621s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 1.5011846691551989 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59768, Requested 1853. Please try again in 1.621s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.7597528517525907 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59612, Requested 1874. Please try again in 1.486s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.7597528517525907 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59612, Requested 1874. Please try again in 1.486s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.7597528517525907 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59612, Requested 1874. Please try again in 1.486s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.7597528517525907 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59612, Requested 1874. Please try again in 1.486s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.7597528517525907 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59612, Requested 1874. Please try again in 1.486s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 0.39177258895476275 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59892, Requested 2034. Please try again in 1.925s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.39177258895476275 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59892, Requested 2034. Please try again in 1.925s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.39177258895476275 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59892, Requested 2034. Please try again in 1.925s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.39177258895476275 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59892, Requested 2034. Please try again in 1.925s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.39177258895476275 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-Lw60FXF38dnbt4jdHY1w8iTH on tokens per min (TPM): Limit 60000, Used 59892, Requested 2034. Please try again in 1.925s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "faithfulness Score: 0.9\n",
      "relevancy Score: 0.85\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   faithfulness  relevancy\n",
       "0           0.9       0.85"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.evaluation import BatchEvalRunner\n",
    "from utils.evaluator import get_batch_eval_results\n",
    "from utils.evaluator import get_batch_eval_df\n",
    "\n",
    "if EVAL:\n",
    "    runner = BatchEvalRunner(\n",
    "        {\n",
    "            \"faithfulness\": faithfullness_evaluator, \n",
    "            \"relevancy\": relevancy_evaluator,\n",
    "        },\n",
    "        workers=8,\n",
    "    )\n",
    "\n",
    "    vector_eval_results = await get_batch_eval_results(runner=runner, qa_dataset=qa_dataset, query_engine=vector_query_engine, num_queries=NUM_BATCH_EVAL)\n",
    "    # summary_eval_results = await get_batch_eval_results(runner=runner, qa_dataset=qa_dataset, query_engine=list_query_engine, num_queries=NUM_BATCH_EVAL)\n",
    "    display(get_batch_eval_df(vector_eval_results))\n",
    "    # display(get_batch_eval_df(summary_eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Build Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=vector_query_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"vector_tool\",\n",
    "            description=(\n",
    "                f\"Useful for retrieving specific context from the documents.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    QueryEngineTool(\n",
    "        query_engine=list_query_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"summary_tool\",\n",
    "            description=(\n",
    "                \"Useful for summarization questions related to the documents.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Anda adalah chatbot yang dapat membantu menjawab pertanyaan tentang berbagai jenis regulasi di Indonesia.\n",
    "\n",
    "Anda HARUS selalu menjawab dengan BAHASA QUERY.\n",
    "Anda TIDAK DIBENARKAN berimajinasi.\n",
    "Anda HANYA DIBENARKAN menjawab pertanyaan berdasarkan dokumen yang telah Anda pelajari.\n",
    "JANGAN MENGGUNAKAN informasi dari luar dokumen yang telah Anda pelajari.\n",
    "Anda memiliki akses ke query tools untuk membantu Anda menemukan informasi yang relevan di basis data regulasi.\n",
    "Berdasarkan informasi konteks dan bukan pengetahuan sebelumnya, jawablah pertanyaan HARUS menggunakan query tools yang tersedia.\n",
    "Gunakan riwayat percakapan sebelumnya atau konteks di atas untuk berinteraksi dan membantu pengguna.\n",
    "\n",
    "Anda memiliki akses ke query tools berikut: \n",
    "- **vector_tool**: Untuk menemukan konteks spesifik dari dokumen\n",
    "- **summary_tool**: Untuk menemukan ringkasan dokumen\n",
    "\n",
    "**Penjelasan Metadata:**\n",
    "Metadata dokumen mencakup informasi berikut:\n",
    "- **file_name**: Nama file dokumen\n",
    "- **title**: Judul dokumen\n",
    "- **sector**: Sektor yang dicakup oleh regulasi\n",
    "- **subsector**: Subsektor yang dicakup oleh regulasi\n",
    "- **regulation_type**: Jenis regulasi (misalnya, Surat Edaran OJK, Peraturan OJK)\n",
    "- **regulation_number**: Nomor regulasi\n",
    "- **effective_date**: Tanggal berlakunya regulasi\n",
    "\n",
    "----------------------------------------------\n",
    "Query: {query_str}\n",
    "Jawaban:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.storage.chat_store import SimpleChatStore\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "\n",
    "chat_store = SimpleChatStore()\n",
    "memory = ChatMemoryBuffer.from_defaults(\n",
    "    token_limit=10000,\n",
    "    chat_store=chat_store,\n",
    "    chat_store_key=\"user1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.callbacks import CallbackManager, LlamaDebugHandler\n",
    "\n",
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.core.agent.legacy.react.base import ReActAgent\n",
    "\n",
    "\n",
    "# agent = OpenAIAgent.from_tools(\n",
    "#     tools=query_engine_tools,\n",
    "#     llm=llm,\n",
    "#     verbose=True,\n",
    "#     memory=memory,\n",
    "#     system_prompt=system_prompt,\n",
    "#     callback_manager=callback_manager,\n",
    "# )\n",
    "\n",
    "agent = ReActAgent.from_tools(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    tools=query_engine_tools,\n",
    "    verbose=True,\n",
    "    system_prompt=system_prompt,\n",
    "    callback_manager=callback_manager,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is Indonesian. I need to use a tool to help me find the information about the effective date of the circular letter No. 15/26/DPbS.\n",
      "Action: vector_tool\n",
      "Action Input: {'input': 'Kapan surat edaran No. 15/26/DPbS mulai berlaku?'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Surat edaran No. 15/26/DPbS mulai berlaku pada tanggal 10 Juli 2013.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: Surat edaran No. 15/26/DPbS mulai berlaku pada tanggal 10 Juli 2013.\n",
      "\u001b[0m**********\n",
      "Trace: chat\n",
      "    |_llm -> 2.901246 seconds\n",
      "    |_function_call -> 12.786671 seconds\n",
      "    |_llm -> 1.237337 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "response_agent = agent.chat(message=query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Surat edaran No. 15/26/DPbS mulai berlaku pada tanggal 10 Juli 2013."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_response\n",
    "\n",
    "display_response(response=response_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 32fe7b0b-2b35-461d-a92c-3df1737a61bf<br>**Similarity:** 0.7375307083129883<br>**Text:** spesifik, Bank wajib menyampaikan rencana tindak (action plan)  \n",
       "yang akan dilakukan. \n",
       "D. \n",
       "Ketent...<br>**Metadata:** {'file_name': 'ojk-sebi-15_26_dpbs-10072013-sebi_perihal_pelaksanaan_pedoman_akuntansi_perbankan_syariah_indonesia_sebi_26_pdf.pdf', 'title': 'Surat Edaran Bank Indonesia perihal Pelaksanaan Pedoman Akuntansi Perbankan Syariah Indonesia', 'sector': 'Perbankan', 'subsector': 'Perbankan Syariah', 'regulation_type': 'SEBI', 'regulation_number': '15/26/DPbS', 'effective_date': '10 Juli 2013', 'retrieval_score': 0.921248197555542}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** a2d20274-ca71-451b-a3b0-dbffd0715e21<br>**Similarity:** 0.7195770144462585<br>**Text:** juta rupiah) sampai dengan Rp 100.000.000,00 (seratus juta \n",
       "rupiah) sebesar 10% (sepuluh persen);...<br>**Metadata:** {'file_name': 'ojk-peraturan_keputusan_mentri-112_kmk_03_2001-06032001-kmk_nomor_112_kmk_03_2001_112_kmk_03_2001_pdf.pdf', 'title': 'Keputusan Menteri Keuangan tentang Pemotongan Pajak Penghasil Pasal 21 atas Penghasilan berupa Uang Pesangon, Uang Tebusan Pensiun, dan Tunjangan Hari Tua atau Jaminan Hari Tua', 'sector': 'IKNB', 'subsector': 'Dana Pensiun', 'regulation_type': 'Peraturan/Keputusan Mentri', 'regulation_number': '112/KMK.03/2001', 'effective_date': '6 Maret 2001', 'retrieval_score': 0.9134289622306824}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 8b06feed-73cc-450f-a81a-f4081a654cf3<br>**Similarity:** 0.7135756611824036<br>**Text:** No. 15/26/DPbS  \n",
       " \n",
       " \n",
       " \n",
       "     Jakarta, 10  Juli  2013    \n",
       " \n",
       " \n",
       "S U R A T    E D A R A N \n",
       " \n",
       "Kepada \n",
       "S...<br>**Metadata:** {'file_name': 'ojk-sebi-15_26_dpbs-10072013-sebi_perihal_pelaksanaan_pedoman_akuntansi_perbankan_syariah_indonesia_sebi_26_pdf.pdf', 'title': 'Surat Edaran Bank Indonesia perihal Pelaksanaan Pedoman Akuntansi Perbankan Syariah Indonesia', 'sector': 'Perbankan', 'subsector': 'Perbankan Syariah', 'regulation_type': 'SEBI', 'regulation_number': '15/26/DPbS', 'effective_date': '10 Juli 2013', 'retrieval_score': 0.9121730327606201}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "for node in response_agent.source_nodes:\n",
    "    display_source_node(node, show_source_metadata=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_store_string = chat_store.json()\n",
    "loaded_chat_store = SimpleChatStore.parse_raw(chat_store_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
